{
    "summary": "The code includes an AI model for generating explanations using API calls and prompts, along with helper functions, constants, and a base class NeuronExplainer. It also handles long prompts and extracts explanations from completion lists while removing extra spaces.",
    "details": [
        {
            "comment": "This code imports necessary modules and defines a few classes for generating explanations of neuron behavior using API calls. It also sets a prefix to be used when generating explanations.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":0-33",
            "content": "\"\"\"Uses API calls to generate explanations of neuron behavior.\"\"\"\nfrom __future__ import annotations\nimport logging\nimport re\nfrom abc import ABC, abstractmethod\nfrom enum import Enum\nfrom typing import Any, Optional, Sequence, Union\nfrom neuron_explainer.activations.activation_records import (\n    calculate_max_activation,\n    format_activation_records,\n    non_zero_activation_proportion,\n)\nfrom neuron_explainer.activations.activations import ActivationRecord\nfrom neuron_explainer.api_client import ApiClient\nfrom neuron_explainer.explanations.few_shot_examples import FewShotExampleSet\nfrom neuron_explainer.explanations.prompt_builder import (\n    HarmonyMessage,\n    PromptBuilder,\n    PromptFormat,\n    Role,\n)\nfrom neuron_explainer.explanations.token_space_few_shot_examples import (\n    TokenSpaceFewShotExampleSet,\n)\nlogger = logging.getLogger(__name__)\n# TODO(williamrs): This prefix may not work well for some things, like predicting the next token.\n# Try other options like \"this neuron activates for\".\nEXPLANATION_PREFIX = \"the main thing this neuron does is find\""
        },
        {
            "comment": "This code defines a class called NeuronExplainer, which is an abstract base class for generating explanations from subclass-specific input data. It also includes helper functions for splitting numbered lists and removing final periods or period-spaces from strings. The code also defines two constants: HARMONY_V4_MODELS (a list of supported model names) and ContextSize (an enumeration representing different context sizes).",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":36-76",
            "content": "def _split_numbered_list(text: str) -> list[str]:\n    \"\"\"Split a numbered list into a list of strings.\"\"\"\n    lines = re.split(r\"\\n\\d+\\.\", text)\n    # Strip the leading whitespace from each line.\n    return [line.lstrip() for line in lines]\ndef _remove_final_period(text: str) -> str:\n    \"\"\"Strip a final period or period-space from a string.\"\"\"\n    if text.endswith(\".\"):\n        return text[:-1]\n    elif text.endswith(\". \"):\n        return text[:-2]\n    return text\nclass ContextSize(int, Enum):\n    TWO_K = 2049\n    FOUR_K = 4097\n    @classmethod\n    def from_int(cls, i: int) -> ContextSize:\n        for context_size in cls:\n            if context_size.value == i:\n                return context_size\n        raise ValueError(f\"{i} is not a valid ContextSize\")\nHARMONY_V4_MODELS = [\"gpt-3.5-turbo\", \"gpt-4\"]\nclass NeuronExplainer(ABC):\n    \"\"\"\n    Abstract base class for Explainer classes that generate explanations from subclass-specific\n    input data.\n    \"\"\"\n    def __init__(\n        self,\n        model_name: str,\n        prompt_format: PromptFormat = PromptFormat.HARMONY_V4,"
        },
        {
            "comment": "This code is defining a class with an initializer and a method for generating explanations. It takes in parameters such as model name, prompt format, context size, max concurrent requests, and cache settings. It also asserts that the model name is appropriate for the prompt format provided, preventing incorrect usage.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":77-100",
            "content": "        # This parameter lets us adjust the length of the prompt when we're generating explanations\n        # using older models with shorter context windows. In the future we can use it to experiment\n        # with longer context windows.\n        context_size: ContextSize = ContextSize.FOUR_K,\n        max_concurrent: Optional[int] = 10,\n        cache: bool = False,\n    ):\n        if prompt_format == PromptFormat.HARMONY_V4:\n            assert model_name in HARMONY_V4_MODELS\n        elif prompt_format in [PromptFormat.NONE, PromptFormat.INSTRUCTION_FOLLOWING]:\n            assert model_name not in HARMONY_V4_MODELS\n        else:\n            raise ValueError(f\"Unhandled prompt format {prompt_format}\")\n        self.model_name = model_name\n        self.prompt_format = prompt_format\n        self.context_size = context_size\n        self.client = ApiClient(model_name=model_name, max_concurrent=max_concurrent, cache=cache)\n    async def generate_explanations(\n        self,\n        *,\n        num_samples: int = 5,\n        max_tokens: int = 60,"
        },
        {
            "comment": "The code is generating explanations based on subclass-specific input data. It first creates a prompt and then passes the prompt along with other parameters to a language model for completion. If the format is HarmonyV4, it expects a list of dictionaries (HarmonyMessage), otherwise a string prompt is passed. The response from the language model is then processed to extract explanations.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":101-127",
            "content": "        temperature: float = 1.0,\n        top_p: float = 1.0,\n        **prompt_kwargs: Any,\n    ) -> list[Any]:\n        \"\"\"Generate explanations based on subclass-specific input data.\"\"\"\n        prompt = self.make_explanation_prompt(max_tokens_for_completion=max_tokens, **prompt_kwargs)\n        generate_kwargs: dict[str, Any] = {\n            \"n\": num_samples,\n            \"max_tokens\": max_tokens,\n            \"temperature\": temperature,\n            \"top_p\": top_p,\n        }\n        if self.prompt_format == PromptFormat.HARMONY_V4:\n            assert isinstance(prompt, list)\n            assert isinstance(prompt[0], dict)  # Really a HarmonyMessage\n            generate_kwargs[\"messages\"] = prompt\n        else:\n            assert isinstance(prompt, str)\n            generate_kwargs[\"prompt\"] = prompt\n        response = await self.client.make_request(**generate_kwargs)\n        logger.debug(\"response in generate_explanations is %s\", response)\n        if self.prompt_format == PromptFormat.HARMONY_V4:\n            explanations = [x[\"message\"][\"content\"] for x in response[\"choices\"]]"
        },
        {
            "comment": "This code defines a class for generating explanations using a prompt and an API. The `make_explanation_prompt` method is used to create a prompt to send to the API, which can be a string or a list of HarmonyMessages depending on the PromptFormat. The `postprocess_explanations` method post-processes the completions returned by the API into a list of explanations (by default it returns the completions as is). If the prompt format is unhandled, a ValueError is raised.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":128-152",
            "content": "        elif self.prompt_format in [PromptFormat.NONE, PromptFormat.INSTRUCTION_FOLLOWING]:\n            explanations = [x[\"text\"] for x in response[\"choices\"]]\n        else:\n            raise ValueError(f\"Unhandled prompt format {self.prompt_format}\")\n        return self.postprocess_explanations(explanations, prompt_kwargs)\n    @abstractmethod\n    def make_explanation_prompt(self, **kwargs: Any) -> Union[str, list[HarmonyMessage]]:\n        \"\"\"\n        Create a prompt to send to the API to generate one or more explanations.\n        A prompt can be a simple string, or a list of HarmonyMessages, depending on the PromptFormat\n        used by this instance.\n        \"\"\"\n        ...\n    def postprocess_explanations(\n        self, completions: list[str], prompt_kwargs: dict[str, Any]\n    ) -> list[Any]:\n        \"\"\"Postprocess the completions returned by the API into a list of explanations.\"\"\"\n        return completions  # no-op by default\n    def _prompt_is_too_long(\n        self, prompt_builder: PromptBuilder, max_tokens_for_completion: int"
        },
        {
            "comment": "This code checks if the prompt length combined with the maximum tokens for completion exceeds the context size. If so, it prints an error and returns True; otherwise, it returns False. The class TokenActivationPairExplainer generates explanations using token/activation pairs and prompts.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":153-176",
            "content": "    ) -> bool:\n        # We'll get a context size error if the prompt itself plus the maximum number of tokens for\n        # the completion is longer than the context size.\n        prompt_length = prompt_builder.prompt_length_in_tokens(self.prompt_format)\n        if prompt_length + max_tokens_for_completion > self.context_size.value:\n            print(\n                f\"Prompt is too long: {prompt_length} + {max_tokens_for_completion} > \"\n                f\"{self.context_size.value}\"\n            )\n            return True\n        return False\nclass TokenActivationPairExplainer(NeuronExplainer):\n    \"\"\"\n    Generate explanations of neuron behavior using a prompt with lists of token/activation pairs.\n    \"\"\"\n    def __init__(\n        self,\n        model_name: str,\n        prompt_format: PromptFormat = PromptFormat.HARMONY_V4,\n        # This parameter lets us adjust the length of the prompt when we're generating explanations\n        # using older models with shorter context windows. In the future we can use it to experiment"
        },
        {
            "comment": "Creates an instance of the class with specified parameters like model name, prompt format, context size, few-shot example set, repeating non-zero activations, maximum concurrent processes, and cache settings. Overrides superclass initializer to set these parameters. Defines a method make_explanation_prompt which takes all_activation_records, max_activation, numbered_list_of_n_explanations as input and returns explanation prompt as output.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":177-199",
            "content": "        # with 8k+ context windows.\n        context_size: ContextSize = ContextSize.FOUR_K,\n        few_shot_example_set: FewShotExampleSet = FewShotExampleSet.ORIGINAL,\n        repeat_non_zero_activations: bool = True,\n        max_concurrent: Optional[int] = 10,\n        cache: bool = False,\n    ):\n        super().__init__(\n            model_name=model_name,\n            prompt_format=prompt_format,\n            max_concurrent=max_concurrent,\n            cache=cache,\n        )\n        self.context_size = context_size\n        self.few_shot_example_set = few_shot_example_set\n        self.repeat_non_zero_activations = repeat_non_zero_activations\n    def make_explanation_prompt(self, **kwargs: Any) -> Union[str, list[HarmonyMessage]]:\n        original_kwargs = kwargs.copy()\n        all_activation_records: Sequence[ActivationRecord] = kwargs.pop(\"all_activation_records\")\n        max_activation: float = kwargs.pop(\"max_activation\")\n        kwargs.setdefault(\"numbered_list_of_n_explanations\", None)\n        numbered_list_of_n_explanations: Optional[int] = kwargs.pop("
        },
        {
            "comment": "This code is setting up parameters for the prompt builder, such as number of explanations and optional omit activation records. It ensures no unexpected kwargs are present and adds a message to the prompt builder explaining the neuron's function in analyzing short documents.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":200-216",
            "content": "            \"numbered_list_of_n_explanations\"\n        )\n        if numbered_list_of_n_explanations is not None:\n            assert numbered_list_of_n_explanations > 0, numbered_list_of_n_explanations\n        # This parameter lets us dynamically shrink the prompt if our initial attempt to create it\n        # results in something that's too long. It's only implemented for the 4k context size.\n        kwargs.setdefault(\"omit_n_activation_records\", 0)\n        omit_n_activation_records: int = kwargs.pop(\"omit_n_activation_records\")\n        max_tokens_for_completion: int = kwargs.pop(\"max_tokens_for_completion\")\n        assert not kwargs, f\"Unexpected kwargs: {kwargs}\"\n        prompt_builder = PromptBuilder()\n        prompt_builder.add_message(\n            Role.SYSTEM,\n            \"We're studying neurons in a neural network. Each neuron looks for some particular \"\n            \"thing in a short document. Look at the parts of the document the neuron activates for \"\n            \"and summarize in a single sentence what the neuron is looking for. Don't list \""
        },
        {
            "comment": "Explains the activation format and its meaning, then selects one activation record from each few-shot example when using a 2k context window.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":217-230",
            "content": "            \"examples of words.\\n\\nThe activation format is token<tab>activation. Activation \"\n            \"values range from 0 to 10. A neuron finding what it's looking for is represented by a \"\n            \"non-zero activation value. The higher the activation value, the stronger the match.\",\n        )\n        few_shot_examples = self.few_shot_example_set.get_examples()\n        num_omitted_activation_records = 0\n        for i, few_shot_example in enumerate(few_shot_examples):\n            few_shot_activation_records = few_shot_example.activation_records\n            if self.context_size == ContextSize.TWO_K:\n                # If we're using a 2k context window, we only have room for one activation record\n                # per few-shot example. (Two few-shot examples with one activation record each seems\n                # to work better than one few-shot example with two activation records, in local\n                # testing.)\n                few_shot_activation_records = few_shot_activation_records[:1]"
        },
        {
            "comment": "If context size is 4K and there are fewer activation records omitted than needed, drop the last one for the few-shot example if there are more than one activation record, then add the per-neuron explanation prompt.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":231-249",
            "content": "            elif (\n                self.context_size == ContextSize.FOUR_K\n                and num_omitted_activation_records < omit_n_activation_records\n            ):\n                # Drop the last activation record for this few-shot example to save tokens, assuming\n                # there are at least two activation records.\n                if len(few_shot_activation_records) > 1:\n                    print(f\"Warning: omitting activation record from few-shot example {i}\")\n                    few_shot_activation_records = few_shot_activation_records[:-1]\n                    num_omitted_activation_records += 1\n            self._add_per_neuron_explanation_prompt(\n                prompt_builder,\n                few_shot_activation_records,\n                i,\n                calculate_max_activation(few_shot_example.activation_records),\n                numbered_list_of_n_explanations=numbered_list_of_n_explanations,\n                explanation=few_shot_example.explanation,\n            )\n        self._add_per_neuron_explanation_prompt("
        },
        {
            "comment": "Code snippet is part of a function that generates an explanation prompt for a model. It includes the activation records, context size, number of few-shot examples, maximum activation value, and a boolean to indicate if an explanation is provided or not. If the prompt exceeds the specified token limit due to the inclusion of activation records, it tries again by omitting one more record until the desired number of omit activation records is reached or the prompt is too long with no opportunity for further omissions.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":250-269",
            "content": "            prompt_builder,\n            # If we're using a 2k context window, we only have room for two of the activation\n            # records.\n            all_activation_records[:2]\n            if self.context_size == ContextSize.TWO_K\n            else all_activation_records,\n            len(few_shot_examples),\n            max_activation,\n            numbered_list_of_n_explanations=numbered_list_of_n_explanations,\n            explanation=None,\n        )\n        # If the prompt is too long *and* we omitted the specified number of activation records, try\n        # again, omitting one more. (If we didn't make the specified number of omissions, we're out\n        # of opportunities to omit records, so we just return the prompt as-is.)\n        if (\n            self._prompt_is_too_long(prompt_builder, max_tokens_for_completion)\n            and num_omitted_activation_records == omit_n_activation_records\n        ):\n            original_kwargs[\"omit_n_activation_records\"] = omit_n_activation_records + 1\n            return self.make_explanation_prompt(**original_kwargs)"
        },
        {
            "comment": "Function that adds per-neuron explanations to the prompt based on activation records and optional parameters.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":270-292",
            "content": "        return prompt_builder.build(self.prompt_format)\n    def _add_per_neuron_explanation_prompt(\n        self,\n        prompt_builder: PromptBuilder,\n        activation_records: Sequence[ActivationRecord],\n        index: int,\n        max_activation: float,\n        # When set, this indicates that the prompt should solicit a numbered list of the given\n        # number of explanations, rather than a single explanation.\n        numbered_list_of_n_explanations: Optional[int],\n        explanation: Optional[str],  # None means this is the end of the full prompt.\n    ) -> None:\n        max_activation = calculate_max_activation(activation_records)\n        user_message = f\"\"\"\nNeuron {index + 1}\nActivations:{format_activation_records(activation_records, max_activation, omit_zeros=False)}\"\"\"\n        # We repeat the non-zero activations only if it was requested and if the proportion of\n        # non-zero activations isn't too high.\n        if (\n            self.repeat_non_zero_activations\n            and non_zero_activation_proportion(activation_records, max_activation) < 0.2"
        },
        {
            "comment": "This code seems to be a part of an explainable AI model. It generates user and assistant messages based on neuron activations, and either provides the explanation for a specific neuron or solicits a numbered list of explanations for all neurons.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":293-315",
            "content": "        ):\n            user_message += (\n                f\"\\nSame activations, but with all zeros filtered out:\"\n                f\"{format_activation_records(activation_records, max_activation, omit_zeros=True)}\"\n            )\n        if numbered_list_of_n_explanations is None:\n            user_message += f\"\\nExplanation of neuron {index + 1} behavior:\"\n            assistant_message = \"\"\n            # For the IF format, we want <|endofprompt|> to come before the explanation prefix.\n            if self.prompt_format == PromptFormat.INSTRUCTION_FOLLOWING:\n                assistant_message += f\" {EXPLANATION_PREFIX}\"\n            else:\n                user_message += f\" {EXPLANATION_PREFIX}\"\n            prompt_builder.add_message(Role.USER, user_message)\n            if explanation is not None:\n                assistant_message += f\" {explanation}.\"\n            if assistant_message:\n                prompt_builder.add_message(Role.ASSISTANT, assistant_message)\n        else:\n            if explanation is None:\n                # For the final neuron, we solicit a numbered list of explanations."
        },
        {
            "comment": "Code snippet adds messages to the prompt_builder depending on the number of explanations. If there are more than one, it creates a numbered list of explanations starting with \"EXPLANATION_PREFIX\". Otherwise, it presents only one explanation as part of a numbered list and then adds the explanation itself. The postprocess_explanations function processes explanations returned by the API.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":316-333",
            "content": "                prompt_builder.add_message(\n                    Role.USER,\n                    f\"\"\"\\nHere are {numbered_list_of_n_explanations} possible explanations for neuron {index + 1} behavior, each beginning with \"{EXPLANATION_PREFIX}\":\\n1. {EXPLANATION_PREFIX}\"\"\",\n                )\n            else:\n                # For the few-shot examples, we only present one explanation, but we present it as a\n                # numbered list.\n                prompt_builder.add_message(\n                    Role.USER,\n                    f\"\"\"\\nHere is 1 possible explanation for neuron {index + 1} behavior, beginning with \"{EXPLANATION_PREFIX}\":\\n1. {EXPLANATION_PREFIX}\"\"\",\n                )\n                prompt_builder.add_message(Role.ASSISTANT, f\" {explanation}.\")\n    def postprocess_explanations(\n        self, completions: list[str], prompt_kwargs: dict[str, Any]\n    ) -> list[Any]:\n        \"\"\"Postprocess the explanations returned by the API\"\"\"\n        numbered_list_of_n_explanations = prompt_kwargs.get(\"numbered_list_of_n_explanations\")"
        },
        {
            "comment": "Code block checks if the \"numbered_list_of_n_explanations\" is None and returns the \"completions\". If it's not None, it iterates through each completion and explanation in a nested loop. For each explanation that starts with EXPLANATION_PREFIX, it removes the prefix and appends the trimmed explanation to all_explanations list. Finally, it returns the list of all explanations.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":334-352",
            "content": "        if numbered_list_of_n_explanations is None:\n            return completions\n        else:\n            all_explanations = []\n            for completion in completions:\n                for explanation in _split_numbered_list(completion):\n                    if explanation.startswith(EXPLANATION_PREFIX):\n                        explanation = explanation[len(EXPLANATION_PREFIX) :]\n                    all_explanations.append(explanation.strip())\n            return all_explanations\nclass TokenSpaceRepresentationExplainer(NeuronExplainer):\n    \"\"\"\n    Generate explanations of arbitrary lists of tokens which disproportionately activate a\n    particular neuron. These lists of tokens can be generated in various ways. As an example, in one\n    set of experiments, we compute the average activation for each neuron conditional on each token\n    that appears in an internet text corpus. We then sort the tokens by their average activation,\n    and show 50 of the top 100 tokens. Other techniques that could be used include taking the top"
        },
        {
            "comment": "This function initializes a new instance of the Explainer class. It takes in parameters like model name, prompt format, context size, few-shot example set, use_few_shot flag, output_numbered_list flag, max_concurrent, and cache. If use_few_shot is True, it asserts that few_shot_example_set is not None and sets self.few_shot_examples accordingly.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":353-380",
            "content": "    tokens in the logit lens or tuned lens representations of a neuron.\n    \"\"\"\n    def __init__(\n        self,\n        model_name: str,\n        prompt_format: PromptFormat = PromptFormat.HARMONY_V4,\n        context_size: ContextSize = ContextSize.FOUR_K,\n        few_shot_example_set: TokenSpaceFewShotExampleSet = TokenSpaceFewShotExampleSet.ORIGINAL,\n        use_few_shot: bool = False,\n        output_numbered_list: bool = False,\n        max_concurrent: Optional[int] = 10,\n        cache: bool = False,\n    ):\n        super().__init__(\n            model_name=model_name,\n            prompt_format=prompt_format,\n            context_size=context_size,\n            max_concurrent=max_concurrent,\n            cache=cache,\n        )\n        self.use_few_shot = use_few_shot\n        self.output_numbered_list = output_numbered_list\n        if self.use_few_shot:\n            assert few_shot_example_set is not None\n            self.few_shot_examples: Optional[TokenSpaceFewShotExampleSet] = few_shot_example_set\n        else:\n            self.few_shot_examples = None"
        },
        {
            "comment": "Code snippet:\n```python\ndef make_explanation_prompt(self, **kwargs: Any) -> Union[str, list[HarmonyMessage]]:\n    tokens: list[str] = kwargs.pop(\"tokens\")\n    max_tokens_for_completion = kwargs.pop(\"max_tokens_for_completion\")\n    assert not kwargs, f\"Unexpected kwargs: {kwargs}\"\n    stringified_tokens = \", \".join([f\"'{t}'\" for t in tokens])\n    prompt_builder = PromptBuilder()\n```\nComment: This function constructs a prompt to ask about the neuron's activation tokens. It takes the \"tokens\" and \"max_tokens_for_completion\" as input arguments, and uses PromptBuilder to build the final prompt.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":381-397",
            "content": "        self.prompt_prefix = (\n            \"We're studying neurons in a neural network. Each neuron looks for some particular \"\n            \"kind of token (which can be a word, or part of a word). Look at the tokens the neuron \"\n            \"activates for (listed below) and summarize in a single sentence what the neuron is \"\n            \"looking for. Don't list examples of words.\"\n        )\n    def make_explanation_prompt(self, **kwargs: Any) -> Union[str, list[HarmonyMessage]]:\n        tokens: list[str] = kwargs.pop(\"tokens\")\n        max_tokens_for_completion = kwargs.pop(\"max_tokens_for_completion\")\n        assert not kwargs, f\"Unexpected kwargs: {kwargs}\"\n        # Note that this does not preserve the precise tokens, as e.g.\n        # f\" {token_with_no_leading_space}\" may be tokenized as \"f{token_with_leading_space}\".\n        # TODO(dan): Try out other variants, including \"\\n\".join(...) and \",\".join(...)\n        stringified_tokens = \", \".join([f\"'{t}'\" for t in tokens])\n        prompt_builder = PromptBuilder()"
        },
        {
            "comment": "This code adds a prompt to the prompt builder. It starts with a system message, then adds few-shot examples if specified and prompts related to neurons. If the prompt is too long, it raises a ValueError. The code also includes an unimplemented feature for numbered lists in few-shot examples.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":398-417",
            "content": "        prompt_builder.add_message(Role.SYSTEM, self.prompt_prefix)\n        if self.use_few_shot:\n            self._add_few_shot_examples(prompt_builder)\n        self._add_neuron_specific_prompt(prompt_builder, stringified_tokens, explanation=None)\n        if self._prompt_is_too_long(prompt_builder, max_tokens_for_completion):\n            raise ValueError(f\"Prompt too long: {prompt_builder.build(self.prompt_format)}\")\n        else:\n            return prompt_builder.build(self.prompt_format)\n    def _add_few_shot_examples(self, prompt_builder: PromptBuilder) -> None:\n        \"\"\"\n        Append few-shot examples to the prompt. Each one consists of a comma-delimited list of\n        tokens and corresponding explanations, as saved in\n        alignment/neuron_explainer/weight_explainer/token_space_few_shot_examples.py.\n        \"\"\"\n        assert self.few_shot_examples is not None\n        few_shot_example_list = self.few_shot_examples.get_examples()\n        if self.output_numbered_list:\n            raise NotImplementedError(\"Numbered list output not supported for few-shot examples\")"
        },
        {
            "comment": "This code adds a neuron-specific prompt to the prompt builder. If the example is not a few shot example, it adds a list of tokens and either an explanation or a starting point for the model to complete with an explanation. The prompt format can be instruction following.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":418-440",
            "content": "        else:\n            for few_shot_example in few_shot_example_list:\n                self._add_neuron_specific_prompt(\n                    prompt_builder,\n                    \", \".join([f\"'{t}'\" for t in few_shot_example.tokens]),\n                    explanation=few_shot_example.explanation,\n                )\n    def _add_neuron_specific_prompt(\n        self,\n        prompt_builder: PromptBuilder,\n        stringified_tokens: str,\n        explanation: Optional[str],\n    ) -> None:\n        \"\"\"\n        Append a neuron-specific prompt to the prompt builder. The prompt consists of a list of\n        tokens followed by either an explanation (if one is passed, for few shot examples) or by\n        the beginning of a completion, to be completed by the model with an explanation.\n        \"\"\"\n        user_message = f\"\\n\\n\\n\\nTokens:\\n{stringified_tokens}\\n\\nExplanation:\\n\"\n        assistant_message = \"\"\n        looking_for = \"This neuron is looking for\"\n        if self.prompt_format == PromptFormat.INSTRUCTION_FOLLOWING:"
        },
        {
            "comment": "This code adds user and assistant messages to a prompt builder based on the prompt format, output numbered list preference, and explanation presence. The postprocess_explanations function then handles multiple explanations in a list format for completions.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":441-463",
            "content": "            # We want <|endofprompt|> to come before \"This neuron is looking for\" in the IF format.\n            assistant_message += looking_for\n        else:\n            user_message += looking_for\n        if self.output_numbered_list:\n            start_of_list = \"\\n1.\"\n            if self.prompt_format == PromptFormat.INSTRUCTION_FOLLOWING:\n                assistant_message += start_of_list\n            else:\n                user_message += start_of_list\n        if explanation is not None:\n            assistant_message += f\"{explanation}.\"\n        prompt_builder.add_message(Role.USER, user_message)\n        if assistant_message:\n            prompt_builder.add_message(Role.ASSISTANT, assistant_message)\n    def postprocess_explanations(\n        self, completions: list[str], prompt_kwargs: dict[str, Any]\n    ) -> list[str]:\n        if self.output_numbered_list:\n            # Each list in the top-level list will have multiple explanations (multiple strings).\n            all_explanations = []\n            for completion in completions:"
        },
        {
            "comment": "This code is parsing a completion list, extracting explanations and removing extra spaces.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/explainer.py\":464-471",
            "content": "                for explanation in _split_numbered_list(completion):\n                    if explanation.startswith(EXPLANATION_PREFIX):\n                        explanation = explanation[len(EXPLANATION_PREFIX) :]\n                    all_explanations.append(explanation.strip())\n            return all_explanations\n        else:\n            # Each element in the top-level list will be an explanation as a string.\n            return [_remove_final_period(explanation) for explanation in completions]"
        }
    ]
}