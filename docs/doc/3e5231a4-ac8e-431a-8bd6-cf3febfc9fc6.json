{
    "summary": "Both comments discuss improvements in simulation object initialization, API calls for neuron activation simulations, token splitting, and prompt builder functions. The code proposes better prompt formats, validates input, predicts activations using few-shot examples, verifies completion validity, and generates explanations for sequence 1 tokens.",
    "details": [
        {
            "comment": "This code uses API calls to simulate neuron activations based on an explanation. It includes classes for activation records, activation scaling, and sequence simulations, as well as functions for formatting activation records, normalizing activations, and building prompts.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":0-32",
            "content": "\"\"\"Uses API calls to simulate neuron activations based on an explanation.\"\"\"\nfrom __future__ import annotations\nimport asyncio\nimport logging\nfrom abc import ABC, abstractmethod\nfrom collections import OrderedDict\nfrom enum import Enum\nfrom typing import Any, Optional, Sequence, Union\nimport numpy as np\nfrom neuron_explainer.activations.activation_records import (\n    calculate_max_activation,\n    format_activation_records,\n    format_sequences_for_simulation,\n    normalize_activations,\n)\nfrom neuron_explainer.activations.activations import ActivationRecord\nfrom neuron_explainer.api_client import ApiClient\nfrom neuron_explainer.explanations.explainer import EXPLANATION_PREFIX\nfrom neuron_explainer.explanations.explanations import ActivationScale, SequenceSimulation\nfrom neuron_explainer.explanations.few_shot_examples import FewShotExampleSet\nfrom neuron_explainer.explanations.prompt_builder import (\n    HarmonyMessage,\n    PromptBuilder,\n    PromptFormat,\n    Role,\n)\nlogger = logging.getLogger(__name__)\n# Our prompts use normalized activation values, which map any range of positive activations to the"
        },
        {
            "comment": "This code defines a SimulationType enum with three simulation types: ALL_AT_ONCE, ONE_AT_A_TIME. It also has a function to compute expected values given normed probabilities by distribution value.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":33-65",
            "content": "# integers from 0 to 10.\nMAX_NORMALIZED_ACTIVATION = 10\nVALID_ACTIVATION_TOKENS_ORDERED = list(str(i) for i in range(MAX_NORMALIZED_ACTIVATION + 1))\nVALID_ACTIVATION_TOKENS = set(VALID_ACTIVATION_TOKENS_ORDERED)\nclass SimulationType(str, Enum):\n    \"\"\"How to simulate neuron activations. Values correspond to subclasses of NeuronSimulator.\"\"\"\n    ALL_AT_ONCE = \"all_at_once\"\n    \"\"\"\n    Use a single prompt with <unknown> tokens; calculate EVs using logprobs.\n    Implemented by ExplanationNeuronSimulator.\n    \"\"\"\n    ONE_AT_A_TIME = \"one_at_a_time\"\n    \"\"\"\n    Use a separate prompt for each token being simulated; calculate EVs using logprobs.\n    Implemented by ExplanationTokenByTokenSimulator.\n    \"\"\"\n    @classmethod\n    def from_string(cls, s: str) -> SimulationType:\n        for simulation_type in SimulationType:\n            if simulation_type.value == s:\n                return simulation_type\n        raise ValueError(f\"Invalid simulation type: {s}\")\ndef compute_expected_value(\n    norm_probabilities_by_distribution_value: OrderedDict[int, float]"
        },
        {
            "comment": "Code chunk 1 (lines 66-91):\n\nThis code calculates the expected value for a distribution given normalized probabilities. It also includes functions to parse top logprobs into a distribution of unnormalized probabilities and compute predicted activation statistics for a token. The code uses numpy arrays for efficient computations and orderd dictionaries for mapping tokens or distribution values to their respective probabilities or logprobs.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":66-91",
            "content": ") -> float:\n    \"\"\"\n    Given a map from distribution values (integers on the range [0, 10]) to normalized\n    probabilities, return an expected value for the distribution.\n    \"\"\"\n    return np.dot(\n        np.array(list(norm_probabilities_by_distribution_value.keys())),\n        np.array(list(norm_probabilities_by_distribution_value.values())),\n    )\ndef parse_top_logprobs(top_logprobs: dict[str, float]) -> OrderedDict[int, float]:\n    \"\"\"\n    Given a map from tokens to logprobs, return a map from distribution values (integers on the\n    range [0, 10]) to unnormalized probabilities (in the sense that they may not sum to 1).\n    \"\"\"\n    probabilities_by_distribution_value = OrderedDict()\n    for token, logprob in top_logprobs.items():\n        if token in VALID_ACTIVATION_TOKENS:\n            token_as_int = int(token)\n            probabilities_by_distribution_value[token_as_int] = np.exp(logprob)\n    return probabilities_by_distribution_value\ndef compute_predicted_activation_stats_for_token(\n    top_logprobs: dict[str, float],"
        },
        {
            "comment": "This function takes the top log probabilities, normalizes them to probabilities, computes the expected value based on these normalized probabilities, and returns both as a tuple. It also includes a helper function that converts a string into a byte array using hexadecimal encoding.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":92-121",
            "content": ") -> tuple[OrderedDict[int, float], float]:\n    probabilities_by_distribution_value = parse_top_logprobs(top_logprobs)\n    total_p_of_distribution_values = sum(probabilities_by_distribution_value.values())\n    norm_probabilities_by_distribution_value = OrderedDict(\n        {\n            distribution_value: p / total_p_of_distribution_values\n            for distribution_value, p in probabilities_by_distribution_value.items()\n        }\n    )\n    expected_value = compute_expected_value(norm_probabilities_by_distribution_value)\n    return (\n        norm_probabilities_by_distribution_value,\n        expected_value,\n    )\n# Adapted from tether/tether/core/encoder.py.\ndef convert_to_byte_array(s: str) -> bytearray:\n    byte_array = bytearray()\n    assert s.startswith(\"bytes:\"), s\n    s = s[6:]\n    while len(s) > 0:\n        if s[0] == \"\\\\\":\n            # Hex encoding.\n            assert s[1] == \"x\"\n            assert len(s) >= 4\n            byte_array.append(int(s[2:4], 16))\n            s = s[4:]\n        else:\n            # Regular ascii encoding."
        },
        {
            "comment": "This code handles the case where a response token is composed of a sequence of bytes. It merges multiple response tokens into a single token until it can be decoded as UTF-8. If a UnicodeDecodeError occurs, it continues to merge previous response tokens into the byte array.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":122-147",
            "content": "            byte_array.append(ord(s[0]))\n            s = s[1:]\n    return byte_array\ndef handle_byte_encoding(\n    response_tokens: Sequence[str], merged_response_index: int\n) -> tuple[str, int]:\n    \"\"\"\n    Handle the case where the current token is a sequence of bytes. This may involve merging\n    multiple response tokens into a single token.\n    \"\"\"\n    response_token = response_tokens[merged_response_index]\n    if response_token.startswith(\"bytes:\"):\n        byte_array = bytearray()\n        while True:\n            byte_array = convert_to_byte_array(response_token) + byte_array\n            try:\n                # If we can decode the byte array as utf-8, then we're done.\n                response_token = byte_array.decode(\"utf-8\")\n                break\n            except UnicodeDecodeError:\n                # If not, then we need to merge the previous response token into the byte\n                # array.\n                merged_response_index -= 1\n                response_token = response_tokens[merged_response_index]"
        },
        {
            "comment": "This function checks if a token from the subject model was split into multiple tokens by the simulator model. It handles cases where different tokenizers are used or Unicode characters are split.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":148-167",
            "content": "    return response_token, merged_response_index\ndef was_token_split(current_token: str, response_tokens: Sequence[str], start_index: int) -> bool:\n    \"\"\"\n    Return whether current_token (a token from the subject model) was split into multiple tokens by\n    the simulator model (as represented by the tokens in response_tokens). start_index is the index\n    in response_tokens at which to begin looking backward to form a complete token. It is usually\n    the first token *before* the delimiter that separates the token from the normalized activation,\n    barring some unusual cases.\n    This mainly happens if the subject model uses a different tokenizer than the simulator model.\n    But it can also happen in cases where Unicode characters are split. This function handles both\n    cases.\n    \"\"\"\n    merged_response_tokens = \"\"\n    merged_response_index = start_index\n    while len(merged_response_tokens) < len(current_token):\n        response_token = response_tokens[merged_response_index]\n        response_token, merged_response_index = handle_byte_encoding("
        },
        {
            "comment": "The code is checking if a token from the subject model was split into two or more tokens by the simulator model. It asserts that merged_response_tokens ends with current_token, calculates the number of merged tokens, and logs a warning if the token was split.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":168-194",
            "content": "            response_tokens, merged_response_index\n        )\n        merged_response_tokens = response_token + merged_response_tokens\n        merged_response_index -= 1\n    # It's possible that merged_response_tokens is longer than current_token at this point,\n    # since the between-lines delimiter may have been merged into the original token. But it\n    # should always be the case that merged_response_tokens ends with current_token.\n    assert merged_response_tokens.endswith(current_token)\n    num_merged_tokens = start_index - merged_response_index\n    token_was_split = num_merged_tokens > 1\n    if token_was_split:\n        logger.debug(\n            \"Warning: token from the subject model was split into 2+ tokens by the simulator model.\"\n        )\n    return token_was_split\ndef parse_simulation_response(\n    response: dict[str, Any],\n    prompt_format: PromptFormat,\n    tokens: Sequence[str],\n) -> SequenceSimulation:\n    \"\"\"\n    Parse an API response to a simulation prompt.\n    Args:\n        response: response from the API"
        },
        {
            "comment": "This function retrieves the text and token data from the response, handling different prompt formats. It then extracts the starting position of the \"<start>\" token in the text, setting up lists for further calculations.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":195-218",
            "content": "        prompt_format: how the prompt was formatted\n        tokens: list of tokens as strings in the sequence where the neuron is being simulated\n    \"\"\"\n    choice = response[\"choices\"][0]\n    if prompt_format == PromptFormat.HARMONY_V4:\n        text = choice[\"message\"][\"content\"]\n    elif prompt_format in [\n        PromptFormat.NONE,\n        PromptFormat.INSTRUCTION_FOLLOWING,\n    ]:\n        text = choice[\"text\"]\n    else:\n        raise ValueError(f\"Unhandled prompt format {prompt_format}\")\n    response_tokens = choice[\"logprobs\"][\"tokens\"]\n    choice[\"logprobs\"][\"token_logprobs\"]\n    top_logprobs = choice[\"logprobs\"][\"top_logprobs\"]\n    token_text_offset = choice[\"logprobs\"][\"text_offset\"]\n    # This only works because the sequence \"<start>\" tokenizes into multiple tokens if it appears in\n    # a text sequence in the prompt.\n    scoring_start = text.rfind(\"<start>\")\n    expected_values = []\n    original_sequence_tokens: list[str] = []\n    distribution_values: list[list[float]] = []\n    distribution_probabilities: list[list[float]] = []"
        },
        {
            "comment": "Checking if the response tokens have reached the end and if the tab token is followed by an \"unknown\" token.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":219-233",
            "content": "    for i in range(2, len(response_tokens)):\n        if len(original_sequence_tokens) == len(tokens):\n            # Make sure we haven't hit some sort of off-by-one error.\n            # TODO(sbills): Generalize this to handle different tokenizers.\n            reached_end = response_tokens[i + 1] == \"<\" and response_tokens[i + 2] == \"end\"\n            assert reached_end, f\"{response_tokens[i-3:i+3]}\"\n            break\n        if token_text_offset[i] >= scoring_start:\n            # We're looking for the first token after a tab. This token should be the text\n            # \"unknown\" if hide_activations=True or a normalized activation (0-10) otherwise.\n            # If it isn't, that means that the tab is not appearing as a delimiter, but rather\n            # as a token, in which case we should move on to the next response token.\n            if response_tokens[i - 1] == \"\\t\":\n                if response_tokens[i] != \"unknown\":\n                    logger.debug(\"Ignoring tab token that is not followed by an 'unknown' token.\")"
        },
        {
            "comment": "Identifying correct token and computing predicted activation stats for the identified token.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":234-255",
            "content": "                    continue\n                # j represents the index of the token in a \"token<tab>activation\" line, barring\n                # one of the unusual cases handled below.\n                j = i - 2\n                current_token = tokens[len(original_sequence_tokens)]\n                if current_token == response_tokens[j] or was_token_split(\n                    current_token, response_tokens, j\n                ):\n                    # We're in the normal case where the tokenization didn't throw off the\n                    # formatting or in the token-was-split case, which we handle the usual way.\n                    current_top_logprobs = top_logprobs[i]\n                    (\n                        norm_probabilities_by_distribution_value,\n                        expected_value,\n                    ) = compute_predicted_activation_stats_for_token(\n                        current_top_logprobs,\n                    )\n                    current_distribution_values = list(\n                        norm_probabilities_by_distribution_value.keys()"
        },
        {
            "comment": "If tokenization resulted in a newline being folded into the token, use dummy values for activation prediction. This is due to the model not observing the original token and a better prompt format should be used to avoid this situation.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":256-271",
            "content": "                    )\n                    current_distribution_probabilities = list(\n                        norm_probabilities_by_distribution_value.values()\n                    )\n                else:\n                    # We're in a case where the tokenization resulted in a newline being folded into\n                    # the token. We can't do our usual prediction of activation stats for the token,\n                    # since the model did not observe the original token. Instead, we use dummy\n                    # values. See the TODO elsewhere in this file about coming up with a better\n                    # prompt format that avoids this situation.\n                    newline_folded_into_token = \"\\n\" in response_tokens[j]\n                    assert (\n                        newline_folded_into_token\n                    ), f\"`{current_token=}` {response_tokens[j-3:j+3]=}\"\n                    logger.debug(\n                        \"Warning: newline before a token<tab>activation line was folded into the token\""
        },
        {
            "comment": "The code is defining a NeuronSimulator class with an abstract method \"simulate\" that takes in a sequence of tokens and returns a SequenceSimulation object. The SequenceSimulation object contains the original token sequence, expected activations, activation scale, distribution values, and distribution probabilities.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":272-296",
            "content": "                    )\n                    current_distribution_values = []\n                    current_distribution_probabilities = []\n                    expected_value = 0.0\n                original_sequence_tokens.append(current_token)\n                distribution_values.append([float(v) for v in current_distribution_values])\n                distribution_probabilities.append(current_distribution_probabilities)\n                expected_values.append(expected_value)\n    return SequenceSimulation(\n        tokens=original_sequence_tokens,\n        expected_activations=expected_values,\n        activation_scale=ActivationScale.SIMULATED_NORMALIZED_ACTIVATIONS,\n        distribution_values=distribution_values,\n        distribution_probabilities=distribution_probabilities,\n    )\nclass NeuronSimulator(ABC):\n    \"\"\"Abstract base class for simulating neuron behavior.\"\"\"\n    @abstractmethod\n    async def simulate(self, tokens: Sequence[str]) -> SequenceSimulation:\n        \"\"\"Simulate the behavior of a neuron based on an explanation.\"\"\""
        },
        {
            "comment": "This code defines a class called \"ExplanationNeuronSimulator\" that simulates neuron behavior based on an explanation. It uses a few-shot prompt with examples of other explanations and activations, allowing for scoring all tokens at once using logprobs. The constructor takes in parameters like model name, explanation, maximum concurrent tasks, example set type, prompt format, and cache settings. It also initializes an \"ApiClient\" object. The class has a method called \"simulate\" that takes a sequence of tokens as input and returns a SequenceSimulation.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":297-328",
            "content": "        ...\nclass ExplanationNeuronSimulator(NeuronSimulator):\n    \"\"\"\n    Simulate neuron behavior based on an explanation.\n    This class uses a few-shot prompt with examples of other explanations and activations. This\n    prompt allows us to score all of the tokens at once using a nifty trick involving logprobs.\n    \"\"\"\n    def __init__(\n        self,\n        model_name: str,\n        explanation: str,\n        max_concurrent: Optional[int] = 10,\n        few_shot_example_set: FewShotExampleSet = FewShotExampleSet.ORIGINAL,\n        prompt_format: PromptFormat = PromptFormat.INSTRUCTION_FOLLOWING,\n        cache: bool = False,\n    ):\n        self.api_client = ApiClient(\n            model_name=model_name, max_concurrent=max_concurrent, cache=cache\n        )\n        self.explanation = explanation\n        self.few_shot_example_set = few_shot_example_set\n        self.prompt_format = prompt_format\n    async def simulate(\n        self,\n        tokens: Sequence[str],\n    ) -> SequenceSimulation:\n        prompt = self.make_simulation_prompt(tokens)"
        },
        {
            "comment": "This code is making an API request to generate a response based on the provided prompt or message, depending on the prompt format. It then parses the response and returns the result. The code includes assertions for validating the input and a TODO comment indicating potential issues with the tokenization format.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":330-351",
            "content": "        generate_kwargs: dict[str, Any] = {\n            \"max_tokens\": 0,\n            \"echo\": True,\n            \"logprobs\": 15,\n        }\n        if self.prompt_format == PromptFormat.HARMONY_V4:\n            assert isinstance(prompt, list)\n            assert isinstance(prompt[0], dict)  # Really a HarmonyMessage\n            generate_kwargs[\"messages\"] = prompt\n        else:\n            assert isinstance(prompt, str)\n            generate_kwargs[\"prompt\"] = prompt\n        response = await self.api_client.make_request(**generate_kwargs)\n        logger.debug(\"response in score_explanation_by_activations is %s\", response)\n        result = parse_simulation_response(response, self.prompt_format, tokens)\n        logger.debug(\"result in score_explanation_by_activations is %s\", result)\n        return result\n    # TODO(sbills): The current token<tab>activation format can result in improper tokenization.\n    # In particular, if the token is itself a tab, we may get a single \"\\t\\t\" token rather than two\n    # \"\\t\" tokens. Consider using a separator that does not appear in any multi-character tokens."
        },
        {
            "comment": "This code creates a prompt for predicting neuron activations using a few-shot example set. It adds a system message with instructions on how to analyze the neurons in a neural network and then appends user messages for each example in the set, including the example itself along with an explanation of the neuron's behavior.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":352-372",
            "content": "    def make_simulation_prompt(self, tokens: Sequence[str]) -> Union[str, list[HarmonyMessage]]:\n        \"\"\"Create a few-shot prompt for predicting neuron activations for the given tokens.\"\"\"\n        # TODO(sbills): The prompts in this file are subtly different from the ones in explainer.py.\n        # Consider reconciling them.\n        prompt_builder = PromptBuilder()\n        prompt_builder.add_message(\n            Role.SYSTEM,\n            \"\"\"We're studying neurons in a neural network.\nEach neuron looks for some particular thing in a short document.\nLook at summary of what the neuron does, and try to predict how it will fire on each token.\nThe activation format is token<tab>activation, activations go from 0 to 10, \"unknown\" indicates an unknown activation. Most activations will be 0.\n\"\"\",\n        )\n        few_shot_examples = self.few_shot_example_set.get_examples()\n        for i, example in enumerate(few_shot_examples):\n            prompt_builder.add_message(\n                Role.USER,\n                f\"\\n\\nNeuron {i + 1}\\nExplanation of neuron {i + 1} behavior: {EXPLANATION_PREFIX} \""
        },
        {
            "comment": "This code snippet is part of a Neuron Simulator that simulates neuron behavior based on an explanation. It adds formatted activation records and messages to a prompt builder, including explanations of neuron behavior for few-shot examples.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":373-398",
            "content": "                f\"{example.explanation}\",\n            )\n            formatted_activation_records = format_activation_records(\n                example.activation_records,\n                calculate_max_activation(example.activation_records),\n                start_indices=example.first_revealed_activation_indices,\n            )\n            prompt_builder.add_message(\n                Role.ASSISTANT, f\"\\nActivations: {formatted_activation_records}\\n\"\n            )\n        prompt_builder.add_message(\n            Role.USER,\n            f\"\\n\\nNeuron {len(few_shot_examples) + 1}\\nExplanation of neuron \"\n            f\"{len(few_shot_examples) + 1} behavior: {EXPLANATION_PREFIX} \"\n            f\"{self.explanation.strip()}\",\n        )\n        prompt_builder.add_message(\n            Role.ASSISTANT, f\"\\nActivations: {format_sequences_for_simulation([tokens])}\"\n        )\n        return prompt_builder.build(self.prompt_format)\nclass ExplanationTokenByTokenSimulator(NeuronSimulator):\n    \"\"\"\n    Simulate neuron behavior based on an explanation."
        },
        {
            "comment": "This class initializes an API client and takes inputs like model name, explanation, max concurrent requests, example set, prompt format, and cache. It asserts that the few-shot example set is not ORIGINAL since this simulator doesn't support it. Then, it performs a simulation using one token prompt per token and calculates expected values from log probabilities. This method is slower compared to ExplanationNeuronSimulator.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":400-425",
            "content": "    Unlike ExplanationNeuronSimulator, this class uses one few-shot prompt per token to calculate\n    expected activations. This is slower. This class gets a one-token completion and calculates an\n    expected value from that token's logprobs.\n    \"\"\"\n    def __init__(\n        self,\n        model_name: str,\n        explanation: str,\n        max_concurrent: Optional[int] = 10,\n        few_shot_example_set: FewShotExampleSet = FewShotExampleSet.NEWER,\n        prompt_format: PromptFormat = PromptFormat.INSTRUCTION_FOLLOWING,\n        cache: bool = False,\n    ):\n        assert (\n            few_shot_example_set != FewShotExampleSet.ORIGINAL\n        ), \"This simulator doesn't support the ORIGINAL few-shot example set.\"\n        self.api_client = ApiClient(\n            model_name=model_name, max_concurrent=max_concurrent, cache=cache\n        )\n        self.explanation = explanation\n        self.few_shot_example_set = few_shot_example_set\n        self.prompt_format = prompt_format\n    async def simulate(\n        self,"
        },
        {
            "comment": "This function collects activation statistics for each token in the input sequence and then normalizes the probabilities by distribution values, expected values, and appends them to their respective lists.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":426-449",
            "content": "        tokens: Sequence[str],\n    ) -> SequenceSimulation:\n        responses_by_token = await asyncio.gather(\n            *[\n                self._get_activation_stats_for_single_token(tokens, self.explanation, token_index)\n                for token_index in range(len(tokens))\n            ]\n        )\n        expected_values, distribution_values, distribution_probabilities = [], [], []\n        for response in responses_by_token:\n            activation_logprobs = response[\"choices\"][0][\"logprobs\"][\"top_logprobs\"][0]\n            (\n                norm_probabilities_by_distribution_value,\n                expected_value,\n            ) = compute_predicted_activation_stats_for_token(\n                activation_logprobs,\n            )\n            distribution_values.append(\n                [float(v) for v in norm_probabilities_by_distribution_value.keys()]\n            )\n            distribution_probabilities.append(\n                list(norm_probabilities_by_distribution_value.values())\n            )\n            expected_values.append(expected_value)"
        },
        {
            "comment": "This code is creating a SequenceSimulation object and logging its result. It also defines an asynchronous function that retrieves activation statistics for a single token using API client, and adds a subprompt to a prompt builder.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":451-478",
            "content": "        result = SequenceSimulation(\n            tokens=list(tokens),  # SequenceSimulation expects List type\n            expected_activations=expected_values,\n            activation_scale=ActivationScale.SIMULATED_NORMALIZED_ACTIVATIONS,\n            distribution_values=distribution_values,\n            distribution_probabilities=distribution_probabilities,\n        )\n        logger.debug(\"result in score_explanation_by_activations is %s\", result)\n        return result\n    async def _get_activation_stats_for_single_token(\n        self,\n        tokens: Sequence[str],\n        explanation: str,\n        token_index_to_score: int,\n    ) -> dict:\n        prompt = self.make_single_token_simulation_prompt(\n            tokens,\n            explanation,\n            token_index_to_score=token_index_to_score,\n        )\n        return await self.api_client.make_request(\n            prompt=prompt, max_tokens=1, echo=False, logprobs=15\n        )\n    def _add_single_token_simulation_subprompt(\n        self,\n        prompt_builder: PromptBuilder,"
        },
        {
            "comment": "Creating trimmed activation record and adding messages to the prompt builder.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":479-507",
            "content": "        activation_record: ActivationRecord,\n        neuron_index: int,\n        explanation: str,\n        token_index_to_score: int,\n        end_of_prompt: bool,\n    ) -> None:\n        trimmed_activation_record = ActivationRecord(\n            tokens=activation_record.tokens[: token_index_to_score + 1],\n            activations=activation_record.activations[: token_index_to_score + 1],\n        )\n        prompt_builder.add_message(\n            Role.USER,\n            f\"\"\"\nNeuron {neuron_index}\nExplanation of neuron {neuron_index} behavior: {EXPLANATION_PREFIX} {explanation.strip()}\nText:\n{\"\".join(trimmed_activation_record.tokens)}\nLast token in the text:\n{trimmed_activation_record.tokens[-1]}\nLast token activation, considering the token in the context in which it appeared in the text:\n\"\"\",\n        )\n        if not end_of_prompt:\n            normalized_activations = normalize_activations(\n                trimmed_activation_record.activations, calculate_max_activation([activation_record])\n            )\n            prompt_builder.add_message("
        },
        {
            "comment": "This function generates a prompt for predicting the neuron's activation on a single token. It involves adding a system message explaining the task and providing few-shot examples.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":508-530",
            "content": "                Role.ASSISTANT, str(normalized_activations[-1]) + (\"\" if end_of_prompt else \"\\n\\n\")\n            )\n    def make_single_token_simulation_prompt(\n        self,\n        tokens: Sequence[str],\n        explanation: str,\n        token_index_to_score: int,\n    ) -> Union[str, list[HarmonyMessage]]:\n        \"\"\"Make a few-shot prompt for predicting the neuron's activation on a single token.\"\"\"\n        assert explanation != \"\"\n        prompt_builder = PromptBuilder()\n        prompt_builder.add_message(\n            Role.SYSTEM,\n            \"\"\"We're studying neurons in a neural network. Each neuron looks for some particular thing in a short document. Look at  an explanation of what the neuron does, and try to predict its activations on a particular token.\nThe activation format is token<tab>activation, and activations range from 0 to 10. Most activations will be 0.\n\"\"\",\n        )\n        few_shot_examples = self.few_shot_example_set.get_examples()\n        for i, example in enumerate(few_shot_examples):"
        },
        {
            "comment": "Generating a prompt to explain neuron behavior and visualize activation records for an example, then adding a message asking to predict the activation of a new neuron on a single token following the same rules.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":531-552",
            "content": "            prompt_builder.add_message(\n                Role.USER,\n                f\"Neuron {i + 1}\\nExplanation of neuron {i + 1} behavior: {EXPLANATION_PREFIX} \"\n                f\"{example.explanation}\\n\",\n            )\n            formatted_activation_records = format_activation_records(\n                example.activation_records,\n                calculate_max_activation(example.activation_records),\n                start_indices=None,\n            )\n            prompt_builder.add_message(\n                Role.ASSISTANT,\n                f\"Activations: {formatted_activation_records}\\n\\n\",\n            )\n        prompt_builder.add_message(\n            Role.SYSTEM,\n            \"Now, we're going predict the activation of a new neuron on a single token, \"\n            \"following the same rules as the examples above. Activations still range from 0 to 10.\",\n        )\n        single_token_example = self.few_shot_example_set.get_single_token_prediction_example()\n        assert single_token_example.token_index_to_score is not None"
        },
        {
            "comment": "This code adds two subprompts to a prompt builder, one for a single token example and another for an activation record. It then returns the final formatted prompt.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":553-580",
            "content": "        self._add_single_token_simulation_subprompt(\n            prompt_builder,\n            single_token_example.activation_records[0],\n            len(few_shot_examples) + 1,\n            explanation,\n            token_index_to_score=single_token_example.token_index_to_score,\n            end_of_prompt=False,\n        )\n        activation_record = ActivationRecord(\n            tokens=list(tokens[: token_index_to_score + 1]),  # ActivationRecord expects List type.\n            activations=[0.0] * len(tokens),\n        )\n        self._add_single_token_simulation_subprompt(\n            prompt_builder,\n            activation_record,\n            len(few_shot_examples) + 2,\n            explanation,\n            token_index_to_score,\n            end_of_prompt=True,\n        )\n        return prompt_builder.build(self.prompt_format, allow_extra_system_messages=True)\ndef _format_record_for_logprob_free_simulation(\n    activation_record: ActivationRecord,\n    include_activations: bool = False,\n    max_activation: Optional[float] = None,"
        },
        {
            "comment": "This code is parsing a completion into a list of simulated activations. If the model did not faithfully reproduce the token sequence, it returns a list of 0s. It also includes an optional normalization of activations based on max_activation parameter.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":581-606",
            "content": ") -> str:\n    response = \"\"\n    if include_activations:\n        assert max_activation is not None\n        assert len(activation_record.tokens) == len(\n            activation_record.activations\n        ), f\"{len(activation_record.tokens)=}, {len(activation_record.activations)=}\"\n        normalized_activations = normalize_activations(\n            activation_record.activations, max_activation=max_activation\n        )\n    for i, token in enumerate(activation_record.tokens):\n        # We use a weird unicode character here to make it easier to parse the response (can split on \"\u0f17\\n\").\n        if include_activations:\n            response += f\"{token}\\t{normalized_activations[i]}\u0f17\\n\"\n        else:\n            response += f\"{token}\\t\u0f17\\n\"\n    return response\ndef _parse_no_logprobs_completion(\n    completion: str,\n    tokens: Sequence[str],\n) -> Sequence[int]:\n    \"\"\"\n    Parse a completion into a list of simulated activations. If the model did not faithfully\n    reproduce the token sequence, return a list of 0s. If the model's activation for a token"
        },
        {
            "comment": "This code checks if the first token is present in the completion and if the number of lines matches the number of tokens. If not, it returns a list of 0s. It then extracts the predicted activations for each token from the completion.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":607-630",
            "content": "    is not an integer betwee 0 and 10, substitute 0.\n    Args:\n        completion: completion from the API\n        tokens: list of tokens as strings in the sequence where the neuron is being simulated\n    \"\"\"\n    zero_prediction = [0] * len(tokens)\n    token_lines = completion.strip(\"\\n\").split(\"\u0f17\\n\")\n    start_line_index = None\n    for i, token_line in enumerate(token_lines):\n        if token_line.startswith(f\"{tokens[0]}\\t\"):\n            start_line_index = i\n            break\n    # If we didn't find the first token, or if the number of lines in the completion doesn't match\n    # the number of tokens, return a list of 0s.\n    if start_line_index is None or len(token_lines) - start_line_index != len(tokens):\n        return zero_prediction\n    predicted_activations = []\n    for i, token_line in enumerate(token_lines[start_line_index:]):\n        if not token_line.startswith(f\"{tokens[i]}\\t\"):\n            return zero_prediction\n        predicted_activation = token_line.split(\"\\t\")[1]\n        if predicted_activation not in VALID_ACTIVATION_TOKENS:"
        },
        {
            "comment": "The code appends deterministic activations to the explanation token sequence.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":631-647",
            "content": "            predicted_activations.append(0)\n        else:\n            predicted_activations.append(int(predicted_activation))\n    return predicted_activations\nclass LogprobFreeExplanationTokenSimulator(NeuronSimulator):\n    \"\"\"\n    Simulate neuron behavior based on an explanation.\n    Unlike ExplanationNeuronSimulator and ExplanationTokenByTokenSimulator, this class does not rely on\n    logprobs to calculate expected activations. Instead, it uses a few-shot prompt that displays all of the\n    tokens at once, and request that the model repeat the tokens with the activations appended. Sampling\n    is with temperature = 0. Thus, the activations are deterministic. Also, each activation for a token\n    is a function of all the activations that came previously and all of the tokens in the sequence, not\n    just the current and previous tokens. In the case where the model does not faithfully reproduce the\n    token sequence, the simulator will return a response where every predicted activation is 0. Example prompt as follows:"
        },
        {
            "comment": "This code is initializing an instance of a simulator. It takes the model name, explanation, maximum concurrent samples, few-shot example set (not ORIGINAL), prompt format, and cache settings as parameters. The assert statement ensures that the few-shot example set is not ORIGINAL because this simulator doesn't support it. It then initializes an instance of ApiClient with the given model name, maximum concurrent samples, and cache settings.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":649-705",
            "content": "    Explanation: Explanation 1\n    Sequence 1 Tokens Without Activations:\n    A\\t_\n    B\\t_\n    C\\t_\n    Sequence 1 Tokens With Activations:\n    A\\t4_\n    B\\t10_\n    C\\t0_\n    Sequence 2 Tokens Without Activations:\n    D\\t_\n    E\\t_\n    F\\t_\n    Sequence 2 Tokens With Activations:\n    D\\t3_\n    E\\t6_\n    F\\t9_\n    Explanation: Explanation 2\n    Sequence 1 Tokens Without Activations:\n    G\\t_\n    H\\t_\n    I\\t_\n    Sequence 1 Tokens With Activations:\n    <start sampling here>\n    G\\t2_\n    H\\t0_\n    I\\t3_\n    \"\"\"\n    def __init__(\n        self,\n        model_name: str,\n        explanation: str,\n        max_concurrent: Optional[int] = 10,\n        few_shot_example_set: FewShotExampleSet = FewShotExampleSet.NEWER,\n        prompt_format: PromptFormat = PromptFormat.HARMONY_V4,\n        cache: bool = False,\n    ):\n        assert (\n            few_shot_example_set != FewShotExampleSet.ORIGINAL\n        ), \"This simulator doesn't support the ORIGINAL few-shot example set.\"\n        self.api_client = ApiClient(\n            model_name=model_name, max_concurrent=max_concurrent, cache=cache"
        },
        {
            "comment": "Code creates a simulation prompt, sends it to API client for processing, and stores the result.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":706-735",
            "content": "        )\n        self.explanation = explanation\n        self.few_shot_example_set = few_shot_example_set\n        self.prompt_format = prompt_format\n    async def simulate(\n        self,\n        tokens: Sequence[str],\n    ) -> SequenceSimulation:\n        prompt = self._make_simulation_prompt(\n            tokens,\n            self.explanation,\n        )\n        response = await self.api_client.make_request(\n            prompt=prompt, echo=False, max_tokens=1000\n        )\n        assert len(response[\"choices\"]) == 1\n        choice = response[\"choices\"][0]\n        if self.prompt_format == PromptFormat.HARMONY_V4:\n            completion = choice[\"message\"][\"content\"]\n        elif self.prompt_format in [PromptFormat.NONE, PromptFormat.INSTRUCTION_FOLLOWING]:\n            completion = choice[\"text\"]\n        else:\n            raise ValueError(f\"Unhandled prompt format {self.prompt_format}\")\n        predicted_activations = _parse_no_logprobs_completion(completion, tokens)\n        result = SequenceSimulation(\n            activation_scale=ActivationScale.SIMULATED_NORMALIZED_ACTIVATIONS,"
        },
        {
            "comment": "Creating a SimulationResult object with expected activations, and None distribution values and probabilities.\n\nFunction to build a simulation prompt using PromptBuilder and add a system message about studying neurons in neural networks.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":736-755",
            "content": "            expected_activations=predicted_activations,\n            # Since the predicted activation is just a sampled token, we don't have a distribution.\n            distribution_values=None,\n            distribution_probabilities=None,\n            tokens=list(tokens),  # SequenceSimulation expects List type\n        )\n        logger.debug(\"result in score_explanation_by_activations is %s\", result)\n        return result\n    def _make_simulation_prompt(\n        self,\n        tokens: Sequence[str],\n        explanation: str,\n    ) -> Union[str, list[HarmonyMessage]]:\n        \"\"\"Make a few-shot prompt for predicting the neuron's activations on a sequence.\"\"\"\n        assert explanation != \"\"\n        prompt_builder = PromptBuilder(allow_extra_system_messages=True)\n        prompt_builder.add_message(\n            Role.SYSTEM,\n            \"\"\"We're studying neurons in a neural network. Each neuron looks for some particular thing in a short document. Look at  an explanation of what the neuron does, and try to predict its activations on a particular token."
        },
        {
            "comment": "This code generates explanations for neuron behavior in a sequence, and for each neuron, it shows the tokens with and without activations. Activation records are used to determine the max activation for that neuron. The output includes an explanation prefix, tokens without and with activations for Sequence 1, and is added to a prompt builder.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":757-773",
            "content": "The activation format is token<tab>activation, and activations range from 0 to 10. Most activations will be 0.\nFor each sequence, you will see the tokens in the sequence where the activations are left blank. You will print the exact same tokens verbatim, but with the activations filled in according to the explanation.\n\"\"\",\n        )\n        few_shot_examples = self.few_shot_example_set.get_examples()\n        for i, example in enumerate(few_shot_examples):\n            few_shot_example_max_activation = calculate_max_activation(example.activation_records)\n            prompt_builder.add_message(\n                Role.USER,\n                f\"Neuron {i + 1}\\nExplanation of neuron {i + 1} behavior: {EXPLANATION_PREFIX} \"\n                f\"{example.explanation}\\n\\n\"\n                f\"Sequence 1 Tokens without Activations:\\n{_format_record_for_logprob_free_simulation(example.activation_records[0], include_activations=False)}\\n\\n\"\n                f\"Sequence 1 Tokens with Activations:\\n\",\n            )\n            prompt_builder.add_message("
        },
        {
            "comment": "This code is building a prompt for an AI model by adding messages to the prompt_builder. It iterates through activation records of an example, adding information about tokens with and without activations for each record. Finally, it adds a message for the next neuron index with its explanation.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":774-792",
            "content": "                Role.ASSISTANT,\n                f\"{_format_record_for_logprob_free_simulation(example.activation_records[0], include_activations=True, max_activation=few_shot_example_max_activation)}\\n\\n\",\n            )\n            for record_index, record in enumerate(example.activation_records[1:]):\n                prompt_builder.add_message(\n                    Role.USER,\n                    f\"Sequence {record_index + 2} Tokens without Activations:\\n{_format_record_for_logprob_free_simulation(record, include_activations=False)}\\n\\n\"\n                    f\"Sequence {record_index + 2} Tokens with Activations:\\n\",\n                )\n                prompt_builder.add_message(\n                    Role.ASSISTANT,\n                    f\"{_format_record_for_logprob_free_simulation(record, include_activations=True, max_activation=few_shot_example_max_activation)}\\n\\n\",\n                )\n        neuron_index = len(few_shot_examples) + 1\n        prompt_builder.add_message(\n            Role.USER,\n            f\"Neuron {neuron_index}\\nExplanation of neuron {neuron_index} behavior: {EXPLANATION_PREFIX} \""
        },
        {
            "comment": "This code generates a formatted explanation for sequence 1 tokens without and with activations, and returns it in a prompt format.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-explainer/neuron_explainer/explanations/simulator.py\":793-797",
            "content": "            f\"{explanation}\\n\\n\"\n            f\"Sequence 1 Tokens without Activations:\\n{_format_record_for_logprob_free_simulation(ActivationRecord(tokens=tokens, activations=[]), include_activations=False)}\\n\\n\"\n            f\"Sequence 1 Tokens with Activations:\\n\",\n        )\n        return prompt_builder.build(self.prompt_format)"
        }
    ]
}