{
    "summary": "This code repository contains tools for generating and analyzing neuron explanations in language models, including public datasets in JSON format and data sources for related neurons and tokens. It also addresses GPT-2 model availability and fixes a GELU implementation bug for inference.",
    "details": [
        {
            "comment": "This repository contains code and tools for the Language models can explain neurons in language models paper. It includes a tool for generating, simulating, and scoring explanations of neuron behavior using the methodology described in the paper. Additionally, there's a tool for viewing neuron activations and explanations accessible online.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/README.md\":0-15",
            "content": "# Automated interpretability\n## Code and tools\nThis repository contains code and tools associated with the [Language models can explain neurons in\nlanguage models](https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html) paper, specifically:\n* Code for automatically generating, simulating, and scoring explanations of neuron behavior using\nthe methodology described in the paper. See the\n[neuron-explainer README](neuron-explainer/README.md) for more information.\nNote: if you run into errors of the form \"Error: Could not find any credentials that grant access to storage account: 'openaipublic' and container: 'neuron-explainer'\".\" you might be able to fix this by signing up for an azure account and specifying the credentials as described in the error message. \n* A tool for viewing neuron activations and explanations, accessible\n[here](https://openaipublic.blob.core.windows.net/neuron-explainer/neuron-viewer/index.html). See\nthe [neuron-viewer README](neuron-viewer/README.md) for more information."
        },
        {
            "comment": "This code provides the location and overview of public datasets for GPT-2 XL neurons and explanations. The datasets include neuron activations and explanations in JSON format, with different sets of tokens and activations provided.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/README.md\":17-32",
            "content": "## Public datasets\nTogether with this code, we're also releasing public datasets of GPT-2 XL neurons and explanations.\nHere's an overview of those datasets.  \n* Neuron activations: `az://openaipublic/neuron-explainer/data/collated-activations/{layer_index}/{neuron_index}.json`\n    - Tokenized text sequences and their activations for the neuron. We\n    provide multiple sets of tokens and activations: top-activating ones, random\n    samples from several quantiles; and a completely random sample. We also provide\n    some basic statistics for the activations.\n    - Each file contains a JSON-formatted\n    [`NeuronRecord`](neuron-explainer/neuron_explainer/activations/activations.py#L89) dataclass.\n* Neuron explanations: `az://openaipublic/neuron-explainer/data/explanations/{layer_index}/{neuron_index}.jsonl`\n    - Scored model-generated explanations of the behavior of the neuron, including simulation results.\n    - Each file contains a JSON-formatted\n    [`NeuronSimulationResults`](neuron-explainer/neuron_explainer/explanations/explanations.py#L146)"
        },
        {
            "comment": "This code defines data sources for related neurons and tokens in a model, stored in Azure Blob Storage. The related neurons include upstream and downstream neurons with the most positive and negative connections, as well as tokens with high average activations or large inbound and outbound weights. Each file contains a JSON-formatted dataclass, which is not included in this repository.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/README.md\":33-44",
            "content": "    dataclass.\n* Related neurons: `az://openaipublic/neuron-explainer/data/related-neurons/weight-based/{layer_index}/{neuron_index}.json`\n    - Lists of the upstream and downstream neurons with the most positive and negative connections (see below for definition).\n    - Each file contains a JSON-formatted dataclass whose definition is not included in this repo.\n* Tokens with high average activations:\n`az://openaipublic/neuron-explainer/data/related-tokens/activation-based/{layer_index}/{neuron_index}.json`\n    - Lists of tokens with the highest average activations for individual neurons, and their average activations.\n    - Each file contains a JSON-formatted [`TokenLookupTableSummaryOfNeuron`](neuron-explainer/neuron_explainer/activations/token_connections.py#L36)\n    dataclass.\n* Tokens with large inbound and outbound weights:\n`az://openaipublic/neuron-explainer/data/related-tokens/weight-based/{layer_index}/{neuron_index}.json`\n    - List of the most-positive and most-negative input and output tokens for individual neurons,"
        },
        {
            "comment": "This code provides information about the availability of neuron activations and explanations for GPT-2 models in different sizes. It also mentions updates on the data, including a bug fix related to the GELU implementation used for inference.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/README.md\":45-54",
            "content": "    as well as the associated weight (see below for definition). \n    - Each file contains a JSON-formatted [`WeightBasedSummaryOfNeuron`](neuron-explainer/neuron_explainer/activations/token_connections.py#L17)\n    dataclass.\nUpdate (July 5, 2023):\nWe also released a set of explanations for GPT-2 Small. The methodology is slightly different from the methodology used for GPT-2 XL so the results aren't directly comparable.\n* Neuron activations: `az://openaipublic/neuron-explainer/gpt2_small_data/collated-activations/{layer_index}/{neuron_index}.json`\n* Neuron explanations: `az://openaipublic/neuron-explainer/gpt2_small_data/explanations/{layer_index}/{neuron_index}.jsonl`\nUpdate (August 30, 2023): We recently discovered a bug in how we performed inference on the GPT-2 series models used for the paper and for these datasets. Specifically, we used an optimized GELU implementation rather than the original GELU implementation associated with GPT-2. While the model\u2019s behavior is very similar across "
        },
        {
            "comment": "This code is explaining the difference in activation values between two configurations for GPT-2 small. It also provides a link to understand the model weight conventions and defines connection weights between neurons and tokens. Additionally, it mentions lists of interesting neurons with some preliminary descriptions.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/README.md\":54-75",
            "content": "these two configurations, the post-MLP activation values we used to generate and simulate explanations differ from the correct values by the following amounts for GPT-2 small:\n- Median: 0.0090\n- 90th percentile: 0.0252\n- 99th percentile: 0.0839\n- 99.9th percentile: 0.1736\n### Definition of connection weights\nRefer to [GPT-2 model code](https://github.com/openai/gpt-2/blob/master/src/model.py) for\nunderstanding of model weight conventions.\n*Neuron-neuron*: For two neurons `(l1, n1)` and `(l2, n2)` with `l1 < l2`, the connection strength is defined as\n`h{l1}.mlp.c_proj.w[:, n1, :] @ diag(h{l2}.ln_2.g) @ h{l2}.mlp.c_fc.w[:, :, n2]`.\n*Neuron-token*: For token `t` and neuron `(l, n)`, the input weight is computed as\n`wte[t, :] @ diag(h{l}.ln_2.g) @ h{l}.mlp.c_fc.w[:, :, n]`\nand the output weight is computed as\n`h{l}.mlp.c_proj.w[:, n, :] @ diag(ln_f.g) @ wte[t, :]`.\n### Misc Lists of Interesting Neurons\nLists of neurons we thought were interesting according to different criteria, with some preliminary descriptions."
        },
        {
            "comment": "These are links to external spreadsheets and documents containing neurons with specific characteristics, such as interesting neurons, high-scoring neurons on random tests, clusters well explained by activation explanation but not by tokens, and neurons sensitive to truncation.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/README.md\":76-79",
            "content": "* [Interesting Neurons (external)](https://docs.google.com/spreadsheets/d/1p7fYs31NU8sJoeKyUx4Mn2laGx8xXfHg_KcIvYiKPpg/edit#gid=0)\n* [Neurons that score high on random, possibly monosemantic? (external)](https://docs.google.com/spreadsheets/d/1TqKFcz-84jyIHLU7VRoTc8BoFBMpbgac-iNBnxVurQ8/edit?usp=sharing)\n* [Clusters of neurons well explained by activation explanation but not by tokens](https://docs.google.com/document/d/1lWhKowpKDdwTMALD_K541cdwgGoQx8DFUSuEe1U2AGE/edit?usp=sharing)\n* [Neurons sensitive to truncation](https://docs.google.com/document/d/1x89TWBvuHcyC2t01EDbJZJ5LQYHozlcS-VUmr5shf_A/edit?usp=sharing)"
        }
    ]
}