{
    "summary": "The code retrieves top-connected neurons and their corresponding layer-neuron pairs, using functions to load JSON files from Azure Blob Storage and memoization.",
    "details": [
        {
            "comment": "This code defines two functions, `load_file_no_cache` and `load_file_az`, for loading data from a file. The first function sends the file path to a server using POST request with JSON body. The second function retrieves the file content using GET request with CORS mode. A memoization function is defined but not used in this code. The `load_file` variable is set based on whether the application is running locally or remotely, and it points to either the local or remote loading function.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-viewer/src/interpAPI.ts\":0-43",
            "content": "import {Neuron} from './types';\nimport {memoizeAsync} from \"./utils\"\nexport const load_file_no_cache = async(path: string) => {\n  const data = {\n    path: path\n  }\n  const url = new URL(\"/load_az\", window.location.href)\n  url.port = '8000';\n  return await (\n    await fetch(url, {\n      method: \"POST\", // or 'PUT'\n      headers: {\n        \"Content-Type\": \"application/json\",\n      },\n      body: JSON.stringify(data),\n    })\n  ).json()\n}\nexport  const load_file_az = async(path: string) => {\n  const res = (\n    await fetch(path, {\n      method: \"GET\",\n      mode: \"cors\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n      },\n    })\n  )\n  if (!res.ok) {\n    console.error(`HTTP error: ${res.status} - ${res.statusText}`);\n    return;\n  }\n  return await res.json()\n}\n// export const load_file = memoizeAsync('load_file', load_file_no_cache)\nexport  const load_file = window.location.host.indexOf('localhost:') === -1 ? load_file_az : load_file_no_cache;\n// # (derived from az://oaialignment/datasets/interp/gpt2_xl/v1/webtext1/len_nomax/n_50000/mlp_post_act/ranked_by_max_activation)"
        },
        {
            "comment": "The code defines constants for the path to neuron records, explanations, and related tokens (weight-based). The previous paths were derived from Azure Storage, but now they are pointing to a public Blob storage in Windows. These paths are used to access the necessary data for interpretation tasks.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-viewer/src/interpAPI.ts\":44-54",
            "content": "// const NEURON_RECORDS_PATH = \"az://oaisbills/rcall/oss/migrated_make_crow_datasets/gpt2_xl_n_50000_64_token/neurons\"\nconst NEURON_RECORDS_PATH = \"https://openaipublic.blob.core.windows.net/neuron-explainer/data/collated-activations\"\n// # (derived from az://oaialignment/datasets/interp/gpt2_xl/v1/webtext1/len_nomax/n_50000/mlp_post_act/ranked_by_max_activation/neurons/explanations/canonical-run-v1)\n// const EXPLANATIONS_PATH = \"az://oaisbills/rcall/oss/migrated_explanation_datasets/canonical_gpt2_xl_all_neurons\"\nconst EXPLANATIONS_PATH = \"https://openaipublic.blob.core.windows.net/neuron-explainer/data/explanations\"\n// weight-based\n// const WHOLE_LAYER_WEIGHT_TOKENS_PATH = \"az://oaidan/rcall/data/interpretability/connections/gpt2-xl/mlp/unnorm_token_representations_uncommon_vanilla\"\n// const WEIGHT_TOKENS_PATH = \"az://oaijeffwu/jeffwu-data/interpretability/neuron-connections/gpt2-xl/weight-based\"\nconst WEIGHT_TOKENS_PATH = \"https://openaipublic.blob.core.windows.net/neuron-explainer/data/related-tokens/weight-based\""
        },
        {
            "comment": "This code defines constants for storage locations of lookup table and connection paths, and functions to retrieve explanations and top tokens based on a given neuron and weight type. The code also uses Azure Blob Storage to load JSON files containing explanation data and token representations.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-viewer/src/interpAPI.ts\":55-72",
            "content": "// lookup table\n// const WHOLE_LAYER_ACTIVATION_TOKENS_PATH = \"az://oaidan/rcall/data/interpretability/connections/gpt2_xl/mlp/unnorm_token_representations_vanilla_and_common_in_colangv2_unigram\"\n// const ACTIVATION_TOKENS_PATH = \"az://oaijeffwu/jeffwu-data/interpretability/neuron-connections/gpt2-xl/lookup-table\"\nconst ACTIVATION_TOKENS_PATH = \"https://openaipublic.blob.core.windows.net/neuron-explainer/data/related-tokens/activation-based\"\n// const CONNECTIONS_PATH = \"az://oaialignment/datasets/interp/connections/gpt2/neuron_space/incl_attn_False\"\nconst CONNECTIONS_PATH = \"https://openaipublic.blob.core.windows.net/neuron-explainer/data/related-neurons/weight-based\"\nexport const get_explanations = async (activeNeuron: Neuron) => {\n  const result = await load_file(`${EXPLANATIONS_PATH}/${activeNeuron.layer}/${activeNeuron.neuron}.jsonl`)\n  return result\n}\nexport const get_top_tokens = async (activeNeuron: Neuron, weightType: string) => {\n  let TOKENS_PATH;\n  if (weightType === 'weight') {\n    TOKENS_PATH = WEIGHT_TOKENS_PATH;"
        },
        {
            "comment": "Checks the weightType and sets the corresponding TOKENS_PATH for loading neuron data. If an invalid weightType is given, throws an error. Loads and returns the neuron data from the specified file path.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-viewer/src/interpAPI.ts\":73-96",
            "content": "  } else if (weightType === 'activation') {\n    TOKENS_PATH = ACTIVATION_TOKENS_PATH;\n  } else {\n    throw new Error(`Invalid weightType: ${weightType}`)\n  }\n  const result = await load_file(`${TOKENS_PATH}/${activeNeuron.layer}/${activeNeuron.neuron}.json`)\n  return result\n  // const result = await load_file_no_cache(`${ORIG_TOKENS_PATH}/${activeNeuron.layer}.json`)\n  // return result.neuron_summaries[activeNeuron.neuron]\n}\nexport const get_top_neuron_connections = async (activeNeuron: Neuron) => {\n    const result = await load_file(`${CONNECTIONS_PATH}/${activeNeuron.layer}/${activeNeuron.neuron}.json`)\n    const res: {[key: string]: [number, number]} = {};\n    [\"input\", \"output\"].forEach((direction) => {\n        const sign = \"positive\"  // \"negative\"\n        const weight_name: string = {output: \"c_proj\", input: \"c_fc\"}[direction] as string;\n        const res_for_dir = result[weight_name];\n        if (res_for_dir === null) {\n          return\n        }\n        // let key = 'top_negative_neurons'\n        c"
        },
        {
            "comment": "This code retrieves the top-connected neurons for a given direction and sign from a result object, maps them to layer, neuron, and weight tuples, and returns the top 10 layer-neuron pairs. It also defines a function `get_neuron_record` that asynchronously loads a JSON file representing a neuron's record based on its layer and neuron ID.",
            "location": "\"/media/root/Toshiba XG3/works/automated-interpretability/docs/src/neuron-viewer/src/interpAPI.ts\":96-111",
            "content": "onst top_neuron_strs = res_for_dir[`top_${sign}_neurons`]  // {layer}_{neuron} strings for each top-connected neuron\n        const top_weights = res_for_dir[`top_${sign}_weights`]\n        const top_layer_neuron_tuples = top_neuron_strs.map((neuron_str: string, i: number) => {\n            const [layer, neuron] = neuron_str.split(\"_\").map((x: string) => parseInt(x))\n            return [layer, neuron, top_weights[i]] as [number, number, number]\n        })\n        res[direction] = top_layer_neuron_tuples.slice(0, 10)\n    })\n    return res\n}\nexport const get_neuron_record = async(activeNeuron: Neuron) => {\n  const result = await load_file(`${NEURON_RECORDS_PATH}/${activeNeuron.layer}/${activeNeuron.neuron}.json`)\n  return result\n}"
        }
    ]
}