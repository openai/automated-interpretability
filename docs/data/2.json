{
    "200": {
        "file_id": 14,
        "content": "        # If it is only a string, the activation is assumed to be 0. This is useful for readability and reducing redundancy in the data.\n        tokens = [t[0] if type(t) is list else t for t in sentence]\n        assert all([type(t) is str for t in tokens]), \"All tokens must be strings\"\n        activations = [float(t[1]) if type(t) is list else 0.0 for t in sentence]\n        assert all([type(t) is float for t in activations]), \"All activations must be floats\"\n        puzzle_activation_records.append(ActivationRecord(tokens=tokens, activations=activations))\n    return Puzzle(\n        name=puzzle_dict[\"name\"],\n        explanation=puzzle_dict[\"explanation\"],\n        activation_records=puzzle_activation_records,\n        false_explanations=puzzle_dict[\"false_explanations\"],\n    )\nPUZZLES_BY_NAME: dict[str, Puzzle] = dict()\nscript_dir = os.path.dirname(os.path.abspath(__file__))\nwith open(os.path.join(script_dir, \"puzzles.json\"), \"r\") as f:\n    puzzle_dicts = json.loads(f.read())\n    for name in puzzle_dicts.keys():",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/puzzles.py:29-49"
    },
    "201": {
        "file_id": 14,
        "content": "The code preprocesses input data for puzzle explanations. It checks if all tokens are strings and all activations are floats, then creates a Puzzle object with name, explanation, activation records, and false explanations. The code reads puzzle data from \"puzzles.json\" file in the same directory.",
        "type": "comment"
    },
    "202": {
        "file_id": 14,
        "content": "        PUZZLES_BY_NAME[name] = convert_puzzle_dict_to_puzzle(puzzle_dicts[name])",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/puzzles.py:50-50"
    },
    "203": {
        "file_id": 14,
        "content": "Assigning puzzle to the name in PUZZLES_BY_NAME dictionary using convert_puzzle_dict_to_puzzle function.",
        "type": "comment"
    },
    "204": {
        "file_id": 15,
        "content": "/neuron-explainer/neuron_explainer/explanations/scoring.py",
        "type": "filepath"
    },
    "205": {
        "file_id": 15,
        "content": "The code generates a scoring function and explanation simulator for assessing neuron evaluations based on correlation and R-squared, using an asynchronous approach. The `make_simulator_and_score` function is created to generate the simulator and score the activation records, returning the scored simulations.",
        "type": "summary"
    },
    "206": {
        "file_id": 15,
        "content": "from __future__ import annotations\nimport asyncio\nimport logging\nfrom typing import Any, Callable, Coroutine, Sequence\nimport numpy as np\nfrom neuron_explainer.activations.activations import ActivationRecord\nfrom neuron_explainer.explanations.calibrated_simulator import (\n    CalibratedNeuronSimulator,\n    LinearCalibratedNeuronSimulator,\n)\nfrom neuron_explainer.explanations.explanations import (\n    ScoredSequenceSimulation,\n    ScoredSimulation,\n    SequenceSimulation,\n)\nfrom neuron_explainer.explanations.simulator import ExplanationNeuronSimulator, NeuronSimulator\ndef flatten_list(list_of_lists: Sequence[Sequence[Any]]) -> list[Any]:\n    return [item for sublist in list_of_lists for item in sublist]\ndef correlation_score(\n    real_activations: Sequence[float] | np.ndarray,\n    predicted_activations: Sequence[float] | np.ndarray,\n) -> float:\n    return np.corrcoef(real_activations, predicted_activations)[0, 1]\ndef score_from_simulation(\n    real_activations: ActivationRecord,\n    simulation: SequenceSimulation,",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/scoring.py:1-34"
    },
    "207": {
        "file_id": 15,
        "content": "Code imports necessary modules and defines three functions:\n1. flatten_list(): Converts a list of lists into a single flat list.\n2. correlation_score(): Computes the correlation coefficient between two sequences of real and predicted activations.\n3. score_from_simulation(): Calculates the correlation score for a given sequence simulation.\n\nThis code is used for scoring simulations based on activation correlations in neuron explanations.",
        "type": "comment"
    },
    "208": {
        "file_id": 15,
        "content": "    score_function: Callable[[Sequence[float] | np.ndarray, Sequence[float] | np.ndarray], float],\n) -> float:\n    return score_function(real_activations.activations, simulation.expected_activations)\ndef rsquared_score_from_sequences(\n    real_activations: Sequence[float] | np.ndarray,\n    predicted_activations: Sequence[float] | np.ndarray,\n) -> float:\n    return float(\n        1\n        - np.mean(np.square(np.array(real_activations) - np.array(predicted_activations)))\n        / np.mean(np.square(np.array(real_activations)))\n    )\ndef absolute_dev_explained_score_from_sequences(\n    real_activations: Sequence[float] | np.ndarray,\n    predicted_activations: Sequence[float] | np.ndarray,\n) -> float:\n    return float(\n        1\n        - np.mean(np.abs(np.array(real_activations) - np.array(predicted_activations)))\n        / np.mean(np.abs(np.array(real_activations)))\n    )\nasync def make_explanation_simulator(\n    explanation: str,\n    calibration_activation_records: Sequence[ActivationRecord],\n    model_name: str,",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/scoring.py:35-65"
    },
    "209": {
        "file_id": 15,
        "content": "This code defines a scoring function that takes in two sequences of floats (or numpy arrays) and returns a score. It provides two specific scoring functions: rsquared_score_from_sequences and absolute_dev_explained_score_from_sequences, which calculate the R-squared and absolute deviation explained scores respectively. These functions are used in make_explanation_simulator, which asynchronously creates an explanation simulator for a given explanation, calibration activation records, and model name.",
        "type": "comment"
    },
    "210": {
        "file_id": 15,
        "content": "    calibrated_simulator_class: type[CalibratedNeuronSimulator] = LinearCalibratedNeuronSimulator,\n) -> CalibratedNeuronSimulator:\n    \"\"\"\n    Make a simulator that uses an explanation to predict activations and calibrates it on the given\n    activation records.\n    \"\"\"\n    simulator = ExplanationNeuronSimulator(model_name, explanation)\n    calibrated_simulator = calibrated_simulator_class(simulator)\n    await calibrated_simulator.calibrate(calibration_activation_records)\n    return calibrated_simulator\nasync def _simulate_and_score_sequence(\n    simulator: NeuronSimulator, activations: ActivationRecord\n) -> ScoredSequenceSimulation:\n    \"\"\"Score an explanation of a neuron by how well it predicts activations on a sentence.\"\"\"\n    simulation = await simulator.simulate(activations.tokens)\n    logging.debug(simulation)\n    rsquared_score = score_from_simulation(activations, simulation, rsquared_score_from_sequences)\n    absolute_dev_explained_score = score_from_simulation(\n        activations, simulation, absolute_dev_explained_score_from_sequences",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/scoring.py:66-86"
    },
    "211": {
        "file_id": 15,
        "content": "This function creates a calibrated neuron simulator using an explanation and a model, and then uses it to simulate and score a sequence of activations. The returned score is based on R-squared and absolute deviation explained scores from sequences.",
        "type": "comment"
    },
    "212": {
        "file_id": 15,
        "content": "    )\n    scored_sequence_simulation = ScoredSequenceSimulation(\n        simulation=simulation,\n        true_activations=activations.activations,\n        ev_correlation_score=score_from_simulation(activations, simulation, correlation_score),\n        rsquared_score=rsquared_score,\n        absolute_dev_explained_score=absolute_dev_explained_score,\n    )\n    return scored_sequence_simulation\ndef aggregate_scored_sequence_simulations(\n    scored_sequence_simulations: list[ScoredSequenceSimulation],\n) -> ScoredSimulation:\n    \"\"\"\n    Aggregate a list of scored sequence simulations. The logic for doing this is non-trivial for EV\n    scores, since we want to calculate the correlation over all activations from all sequences at\n    once rather than simply averaging per-sequence correlations.\n    \"\"\"\n    all_true_activations: list[float] = []\n    all_expected_values: list[float] = []\n    for scored_sequence_simulation in scored_sequence_simulations:\n        all_true_activations.extend(scored_sequence_simulation.true_activations or [])",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/scoring.py:87-109"
    },
    "213": {
        "file_id": 15,
        "content": "Code calculates and aggregates scored sequence simulations for each activation in a list of activations.\nIt combines true activations and expected values from all sequences to calculate the correlation score.",
        "type": "comment"
    },
    "214": {
        "file_id": 15,
        "content": "        all_expected_values.extend(scored_sequence_simulation.simulation.expected_activations)\n    ev_correlation_score = (\n        correlation_score(all_true_activations, all_expected_values)\n        if len(all_true_activations) > 0\n        else None\n    )\n    rsquared_score = rsquared_score_from_sequences(all_true_activations, all_expected_values)\n    absolute_dev_explained_score = absolute_dev_explained_score_from_sequences(\n        all_true_activations, all_expected_values\n    )\n    return ScoredSimulation(\n        scored_sequence_simulations=scored_sequence_simulations,\n        ev_correlation_score=ev_correlation_score,\n        rsquared_score=rsquared_score,\n        absolute_dev_explained_score=absolute_dev_explained_score,\n    )\nasync def simulate_and_score(\n    simulator: NeuronSimulator,\n    activation_records: Sequence[ActivationRecord],\n) -> ScoredSimulation:\n    \"\"\"\n    Score an explanation of a neuron by how well it predicts activations on the given text\n    sequences.\n    \"\"\"\n    scored_sequence_simulations = await asyncio.gather(",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/scoring.py:110-137"
    },
    "215": {
        "file_id": 15,
        "content": "Code performs the following:\n1. Extends the list of all_expected_values with simulation's expected activation values.\n2. Calculates Ev correlation score, R squared score, and absolute dev explained score for explanation prediction accuracy.\n3. Returns a ScoredSimulation object with scores and simulations.",
        "type": "comment"
    },
    "216": {
        "file_id": 15,
        "content": "        *[\n            _simulate_and_score_sequence(\n                simulator,\n                activation_record,\n            )\n            for activation_record in activation_records\n        ]\n    )\n    return aggregate_scored_sequence_simulations(scored_sequence_simulations)\nasync def make_simulator_and_score(\n    make_simulator: Coroutine[None, None, NeuronSimulator],\n    activation_records: Sequence[ActivationRecord],\n) -> ScoredSimulation:\n    \"\"\"Chain together creating the simulator and using it to score activation records.\"\"\"\n    simulator = await make_simulator\n    return await simulate_and_score(simulator, activation_records)",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/scoring.py:138-155"
    },
    "217": {
        "file_id": 15,
        "content": "This code defines a function called `make_simulator_and_score` that takes in a coroutine for creating a simulator and a sequence of activation records. It then creates the simulator and uses it to score the activation records, returning the scored simulations. The code is asynchronous and uses awaitable operations.",
        "type": "comment"
    },
    "218": {
        "file_id": 16,
        "content": "/neuron-explainer/neuron_explainer/explanations/simulator.py",
        "type": "filepath"
    },
    "219": {
        "file_id": 16,
        "content": "Both comments discuss improvements in simulation object initialization, API calls for neuron activation simulations, token splitting, and prompt builder functions. The code proposes better prompt formats, validates input, predicts activations using few-shot examples, verifies completion validity, and generates explanations for sequence 1 tokens.",
        "type": "summary"
    },
    "220": {
        "file_id": 16,
        "content": "\"\"\"Uses API calls to simulate neuron activations based on an explanation.\"\"\"\nfrom __future__ import annotations\nimport asyncio\nimport logging\nfrom abc import ABC, abstractmethod\nfrom collections import OrderedDict\nfrom enum import Enum\nfrom typing import Any, Optional, Sequence, Union\nimport numpy as np\nfrom neuron_explainer.activations.activation_records import (\n    calculate_max_activation,\n    format_activation_records,\n    format_sequences_for_simulation,\n    normalize_activations,\n)\nfrom neuron_explainer.activations.activations import ActivationRecord\nfrom neuron_explainer.api_client import ApiClient\nfrom neuron_explainer.explanations.explainer import EXPLANATION_PREFIX\nfrom neuron_explainer.explanations.explanations import ActivationScale, SequenceSimulation\nfrom neuron_explainer.explanations.few_shot_examples import FewShotExampleSet\nfrom neuron_explainer.explanations.prompt_builder import (\n    HarmonyMessage,\n    PromptBuilder,\n    PromptFormat,\n    Role,\n)\nlogger = logging.getLogger(__name__)\n# Our prompts use normalized activation values, which map any range of positive activations to the",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:1-33"
    },
    "221": {
        "file_id": 16,
        "content": "This code uses API calls to simulate neuron activations based on an explanation. It includes classes for activation records, activation scaling, and sequence simulations, as well as functions for formatting activation records, normalizing activations, and building prompts.",
        "type": "comment"
    },
    "222": {
        "file_id": 16,
        "content": "# integers from 0 to 10.\nMAX_NORMALIZED_ACTIVATION = 10\nVALID_ACTIVATION_TOKENS_ORDERED = list(str(i) for i in range(MAX_NORMALIZED_ACTIVATION + 1))\nVALID_ACTIVATION_TOKENS = set(VALID_ACTIVATION_TOKENS_ORDERED)\nclass SimulationType(str, Enum):\n    \"\"\"How to simulate neuron activations. Values correspond to subclasses of NeuronSimulator.\"\"\"\n    ALL_AT_ONCE = \"all_at_once\"\n    \"\"\"\n    Use a single prompt with <unknown> tokens; calculate EVs using logprobs.\n    Implemented by ExplanationNeuronSimulator.\n    \"\"\"\n    ONE_AT_A_TIME = \"one_at_a_time\"\n    \"\"\"\n    Use a separate prompt for each token being simulated; calculate EVs using logprobs.\n    Implemented by ExplanationTokenByTokenSimulator.\n    \"\"\"\n    @classmethod\n    def from_string(cls, s: str) -> SimulationType:\n        for simulation_type in SimulationType:\n            if simulation_type.value == s:\n                return simulation_type\n        raise ValueError(f\"Invalid simulation type: {s}\")\ndef compute_expected_value(\n    norm_probabilities_by_distribution_value: OrderedDict[int, float]",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:34-66"
    },
    "223": {
        "file_id": 16,
        "content": "This code defines a SimulationType enum with three simulation types: ALL_AT_ONCE, ONE_AT_A_TIME. It also has a function to compute expected values given normed probabilities by distribution value.",
        "type": "comment"
    },
    "224": {
        "file_id": 16,
        "content": ") -> float:\n    \"\"\"\n    Given a map from distribution values (integers on the range [0, 10]) to normalized\n    probabilities, return an expected value for the distribution.\n    \"\"\"\n    return np.dot(\n        np.array(list(norm_probabilities_by_distribution_value.keys())),\n        np.array(list(norm_probabilities_by_distribution_value.values())),\n    )\ndef parse_top_logprobs(top_logprobs: dict[str, float]) -> OrderedDict[int, float]:\n    \"\"\"\n    Given a map from tokens to logprobs, return a map from distribution values (integers on the\n    range [0, 10]) to unnormalized probabilities (in the sense that they may not sum to 1).\n    \"\"\"\n    probabilities_by_distribution_value = OrderedDict()\n    for token, logprob in top_logprobs.items():\n        if token in VALID_ACTIVATION_TOKENS:\n            token_as_int = int(token)\n            probabilities_by_distribution_value[token_as_int] = np.exp(logprob)\n    return probabilities_by_distribution_value\ndef compute_predicted_activation_stats_for_token(\n    top_logprobs: dict[str, float],",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:67-92"
    },
    "225": {
        "file_id": 16,
        "content": "Code chunk 1 (lines 66-91):\n\nThis code calculates the expected value for a distribution given normalized probabilities. It also includes functions to parse top logprobs into a distribution of unnormalized probabilities and compute predicted activation statistics for a token. The code uses numpy arrays for efficient computations and orderd dictionaries for mapping tokens or distribution values to their respective probabilities or logprobs.",
        "type": "comment"
    },
    "226": {
        "file_id": 16,
        "content": ") -> tuple[OrderedDict[int, float], float]:\n    probabilities_by_distribution_value = parse_top_logprobs(top_logprobs)\n    total_p_of_distribution_values = sum(probabilities_by_distribution_value.values())\n    norm_probabilities_by_distribution_value = OrderedDict(\n        {\n            distribution_value: p / total_p_of_distribution_values\n            for distribution_value, p in probabilities_by_distribution_value.items()\n        }\n    )\n    expected_value = compute_expected_value(norm_probabilities_by_distribution_value)\n    return (\n        norm_probabilities_by_distribution_value,\n        expected_value,\n    )\n# Adapted from tether/tether/core/encoder.py.\ndef convert_to_byte_array(s: str) -> bytearray:\n    byte_array = bytearray()\n    assert s.startswith(\"bytes:\"), s\n    s = s[6:]\n    while len(s) > 0:\n        if s[0] == \"\\\\\":\n            # Hex encoding.\n            assert s[1] == \"x\"\n            assert len(s) >= 4\n            byte_array.append(int(s[2:4], 16))\n            s = s[4:]\n        else:\n            # Regular ascii encoding.",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:93-122"
    },
    "227": {
        "file_id": 16,
        "content": "This function takes the top log probabilities, normalizes them to probabilities, computes the expected value based on these normalized probabilities, and returns both as a tuple. It also includes a helper function that converts a string into a byte array using hexadecimal encoding.",
        "type": "comment"
    },
    "228": {
        "file_id": 16,
        "content": "            byte_array.append(ord(s[0]))\n            s = s[1:]\n    return byte_array\ndef handle_byte_encoding(\n    response_tokens: Sequence[str], merged_response_index: int\n) -> tuple[str, int]:\n    \"\"\"\n    Handle the case where the current token is a sequence of bytes. This may involve merging\n    multiple response tokens into a single token.\n    \"\"\"\n    response_token = response_tokens[merged_response_index]\n    if response_token.startswith(\"bytes:\"):\n        byte_array = bytearray()\n        while True:\n            byte_array = convert_to_byte_array(response_token) + byte_array\n            try:\n                # If we can decode the byte array as utf-8, then we're done.\n                response_token = byte_array.decode(\"utf-8\")\n                break\n            except UnicodeDecodeError:\n                # If not, then we need to merge the previous response token into the byte\n                # array.\n                merged_response_index -= 1\n                response_token = response_tokens[merged_response_index]",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:123-148"
    },
    "229": {
        "file_id": 16,
        "content": "This code handles the case where a response token is composed of a sequence of bytes. It merges multiple response tokens into a single token until it can be decoded as UTF-8. If a UnicodeDecodeError occurs, it continues to merge previous response tokens into the byte array.",
        "type": "comment"
    },
    "230": {
        "file_id": 16,
        "content": "    return response_token, merged_response_index\ndef was_token_split(current_token: str, response_tokens: Sequence[str], start_index: int) -> bool:\n    \"\"\"\n    Return whether current_token (a token from the subject model) was split into multiple tokens by\n    the simulator model (as represented by the tokens in response_tokens). start_index is the index\n    in response_tokens at which to begin looking backward to form a complete token. It is usually\n    the first token *before* the delimiter that separates the token from the normalized activation,\n    barring some unusual cases.\n    This mainly happens if the subject model uses a different tokenizer than the simulator model.\n    But it can also happen in cases where Unicode characters are split. This function handles both\n    cases.\n    \"\"\"\n    merged_response_tokens = \"\"\n    merged_response_index = start_index\n    while len(merged_response_tokens) < len(current_token):\n        response_token = response_tokens[merged_response_index]\n        response_token, merged_response_index = handle_byte_encoding(",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:149-168"
    },
    "231": {
        "file_id": 16,
        "content": "This function checks if a token from the subject model was split into multiple tokens by the simulator model. It handles cases where different tokenizers are used or Unicode characters are split.",
        "type": "comment"
    },
    "232": {
        "file_id": 16,
        "content": "            response_tokens, merged_response_index\n        )\n        merged_response_tokens = response_token + merged_response_tokens\n        merged_response_index -= 1\n    # It's possible that merged_response_tokens is longer than current_token at this point,\n    # since the between-lines delimiter may have been merged into the original token. But it\n    # should always be the case that merged_response_tokens ends with current_token.\n    assert merged_response_tokens.endswith(current_token)\n    num_merged_tokens = start_index - merged_response_index\n    token_was_split = num_merged_tokens > 1\n    if token_was_split:\n        logger.debug(\n            \"Warning: token from the subject model was split into 2+ tokens by the simulator model.\"\n        )\n    return token_was_split\ndef parse_simulation_response(\n    response: dict[str, Any],\n    prompt_format: PromptFormat,\n    tokens: Sequence[str],\n) -> SequenceSimulation:\n    \"\"\"\n    Parse an API response to a simulation prompt.\n    Args:\n        response: response from the API",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:169-195"
    },
    "233": {
        "file_id": 16,
        "content": "The code is checking if a token from the subject model was split into two or more tokens by the simulator model. It asserts that merged_response_tokens ends with current_token, calculates the number of merged tokens, and logs a warning if the token was split.",
        "type": "comment"
    },
    "234": {
        "file_id": 16,
        "content": "        prompt_format: how the prompt was formatted\n        tokens: list of tokens as strings in the sequence where the neuron is being simulated\n    \"\"\"\n    choice = response[\"choices\"][0]\n    if prompt_format == PromptFormat.HARMONY_V4:\n        text = choice[\"message\"][\"content\"]\n    elif prompt_format in [\n        PromptFormat.NONE,\n        PromptFormat.INSTRUCTION_FOLLOWING,\n    ]:\n        text = choice[\"text\"]\n    else:\n        raise ValueError(f\"Unhandled prompt format {prompt_format}\")\n    response_tokens = choice[\"logprobs\"][\"tokens\"]\n    choice[\"logprobs\"][\"token_logprobs\"]\n    top_logprobs = choice[\"logprobs\"][\"top_logprobs\"]\n    token_text_offset = choice[\"logprobs\"][\"text_offset\"]\n    # This only works because the sequence \"<start>\" tokenizes into multiple tokens if it appears in\n    # a text sequence in the prompt.\n    scoring_start = text.rfind(\"<start>\")\n    expected_values = []\n    original_sequence_tokens: list[str] = []\n    distribution_values: list[list[float]] = []\n    distribution_probabilities: list[list[float]] = []",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:196-219"
    },
    "235": {
        "file_id": 16,
        "content": "This function retrieves the text and token data from the response, handling different prompt formats. It then extracts the starting position of the \"<start>\" token in the text, setting up lists for further calculations.",
        "type": "comment"
    },
    "236": {
        "file_id": 16,
        "content": "    for i in range(2, len(response_tokens)):\n        if len(original_sequence_tokens) == len(tokens):\n            # Make sure we haven't hit some sort of off-by-one error.\n            # TODO(sbills): Generalize this to handle different tokenizers.\n            reached_end = response_tokens[i + 1] == \"<\" and response_tokens[i + 2] == \"end\"\n            assert reached_end, f\"{response_tokens[i-3:i+3]}\"\n            break\n        if token_text_offset[i] >= scoring_start:\n            # We're looking for the first token after a tab. This token should be the text\n            # \"unknown\" if hide_activations=True or a normalized activation (0-10) otherwise.\n            # If it isn't, that means that the tab is not appearing as a delimiter, but rather\n            # as a token, in which case we should move on to the next response token.\n            if response_tokens[i - 1] == \"\\t\":\n                if response_tokens[i] != \"unknown\":\n                    logger.debug(\"Ignoring tab token that is not followed by an 'unknown' token.\")",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:220-234"
    },
    "237": {
        "file_id": 16,
        "content": "Checking if the response tokens have reached the end and if the tab token is followed by an \"unknown\" token.",
        "type": "comment"
    },
    "238": {
        "file_id": 16,
        "content": "                    continue\n                # j represents the index of the token in a \"token<tab>activation\" line, barring\n                # one of the unusual cases handled below.\n                j = i - 2\n                current_token = tokens[len(original_sequence_tokens)]\n                if current_token == response_tokens[j] or was_token_split(\n                    current_token, response_tokens, j\n                ):\n                    # We're in the normal case where the tokenization didn't throw off the\n                    # formatting or in the token-was-split case, which we handle the usual way.\n                    current_top_logprobs = top_logprobs[i]\n                    (\n                        norm_probabilities_by_distribution_value,\n                        expected_value,\n                    ) = compute_predicted_activation_stats_for_token(\n                        current_top_logprobs,\n                    )\n                    current_distribution_values = list(\n                        norm_probabilities_by_distribution_value.keys()",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:235-256"
    },
    "239": {
        "file_id": 16,
        "content": "Identifying correct token and computing predicted activation stats for the identified token.",
        "type": "comment"
    },
    "240": {
        "file_id": 16,
        "content": "                    )\n                    current_distribution_probabilities = list(\n                        norm_probabilities_by_distribution_value.values()\n                    )\n                else:\n                    # We're in a case where the tokenization resulted in a newline being folded into\n                    # the token. We can't do our usual prediction of activation stats for the token,\n                    # since the model did not observe the original token. Instead, we use dummy\n                    # values. See the TODO elsewhere in this file about coming up with a better\n                    # prompt format that avoids this situation.\n                    newline_folded_into_token = \"\\n\" in response_tokens[j]\n                    assert (\n                        newline_folded_into_token\n                    ), f\"`{current_token=}` {response_tokens[j-3:j+3]=}\"\n                    logger.debug(\n                        \"Warning: newline before a token<tab>activation line was folded into the token\"",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:257-272"
    },
    "241": {
        "file_id": 16,
        "content": "If tokenization resulted in a newline being folded into the token, use dummy values for activation prediction. This is due to the model not observing the original token and a better prompt format should be used to avoid this situation.",
        "type": "comment"
    },
    "242": {
        "file_id": 16,
        "content": "                    )\n                    current_distribution_values = []\n                    current_distribution_probabilities = []\n                    expected_value = 0.0\n                original_sequence_tokens.append(current_token)\n                distribution_values.append([float(v) for v in current_distribution_values])\n                distribution_probabilities.append(current_distribution_probabilities)\n                expected_values.append(expected_value)\n    return SequenceSimulation(\n        tokens=original_sequence_tokens,\n        expected_activations=expected_values,\n        activation_scale=ActivationScale.SIMULATED_NORMALIZED_ACTIVATIONS,\n        distribution_values=distribution_values,\n        distribution_probabilities=distribution_probabilities,\n    )\nclass NeuronSimulator(ABC):\n    \"\"\"Abstract base class for simulating neuron behavior.\"\"\"\n    @abstractmethod\n    async def simulate(self, tokens: Sequence[str]) -> SequenceSimulation:\n        \"\"\"Simulate the behavior of a neuron based on an explanation.\"\"\"",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:273-297"
    },
    "243": {
        "file_id": 16,
        "content": "The code is defining a NeuronSimulator class with an abstract method \"simulate\" that takes in a sequence of tokens and returns a SequenceSimulation object. The SequenceSimulation object contains the original token sequence, expected activations, activation scale, distribution values, and distribution probabilities.",
        "type": "comment"
    },
    "244": {
        "file_id": 16,
        "content": "        ...\nclass ExplanationNeuronSimulator(NeuronSimulator):\n    \"\"\"\n    Simulate neuron behavior based on an explanation.\n    This class uses a few-shot prompt with examples of other explanations and activations. This\n    prompt allows us to score all of the tokens at once using a nifty trick involving logprobs.\n    \"\"\"\n    def __init__(\n        self,\n        model_name: str,\n        explanation: str,\n        max_concurrent: Optional[int] = 10,\n        few_shot_example_set: FewShotExampleSet = FewShotExampleSet.ORIGINAL,\n        prompt_format: PromptFormat = PromptFormat.INSTRUCTION_FOLLOWING,\n        cache: bool = False,\n    ):\n        self.api_client = ApiClient(\n            model_name=model_name, max_concurrent=max_concurrent, cache=cache\n        )\n        self.explanation = explanation\n        self.few_shot_example_set = few_shot_example_set\n        self.prompt_format = prompt_format\n    async def simulate(\n        self,\n        tokens: Sequence[str],\n    ) -> SequenceSimulation:\n        prompt = self.make_simulation_prompt(tokens)",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:298-329"
    },
    "245": {
        "file_id": 16,
        "content": "This code defines a class called \"ExplanationNeuronSimulator\" that simulates neuron behavior based on an explanation. It uses a few-shot prompt with examples of other explanations and activations, allowing for scoring all tokens at once using logprobs. The constructor takes in parameters like model name, explanation, maximum concurrent tasks, example set type, prompt format, and cache settings. It also initializes an \"ApiClient\" object. The class has a method called \"simulate\" that takes a sequence of tokens as input and returns a SequenceSimulation.",
        "type": "comment"
    },
    "246": {
        "file_id": 16,
        "content": "        generate_kwargs: dict[str, Any] = {\n            \"max_tokens\": 0,\n            \"echo\": True,\n            \"logprobs\": 15,\n        }\n        if self.prompt_format == PromptFormat.HARMONY_V4:\n            assert isinstance(prompt, list)\n            assert isinstance(prompt[0], dict)  # Really a HarmonyMessage\n            generate_kwargs[\"messages\"] = prompt\n        else:\n            assert isinstance(prompt, str)\n            generate_kwargs[\"prompt\"] = prompt\n        response = await self.api_client.make_request(**generate_kwargs)\n        logger.debug(\"response in score_explanation_by_activations is %s\", response)\n        result = parse_simulation_response(response, self.prompt_format, tokens)\n        logger.debug(\"result in score_explanation_by_activations is %s\", result)\n        return result\n    # TODO(sbills): The current token<tab>activation format can result in improper tokenization.\n    # In particular, if the token is itself a tab, we may get a single \"\\t\\t\" token rather than two\n    # \"\\t\" tokens. Consider using a separator that does not appear in any multi-character tokens.",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:331-352"
    },
    "247": {
        "file_id": 16,
        "content": "This code is making an API request to generate a response based on the provided prompt or message, depending on the prompt format. It then parses the response and returns the result. The code includes assertions for validating the input and a TODO comment indicating potential issues with the tokenization format.",
        "type": "comment"
    },
    "248": {
        "file_id": 16,
        "content": "    def make_simulation_prompt(self, tokens: Sequence[str]) -> Union[str, list[HarmonyMessage]]:\n        \"\"\"Create a few-shot prompt for predicting neuron activations for the given tokens.\"\"\"\n        # TODO(sbills): The prompts in this file are subtly different from the ones in explainer.py.\n        # Consider reconciling them.\n        prompt_builder = PromptBuilder()\n        prompt_builder.add_message(\n            Role.SYSTEM,\n            \"\"\"We're studying neurons in a neural network.\nEach neuron looks for some particular thing in a short document.\nLook at summary of what the neuron does, and try to predict how it will fire on each token.\nThe activation format is token<tab>activation, activations go from 0 to 10, \"unknown\" indicates an unknown activation. Most activations will be 0.\n\"\"\",\n        )\n        few_shot_examples = self.few_shot_example_set.get_examples()\n        for i, example in enumerate(few_shot_examples):\n            prompt_builder.add_message(\n                Role.USER,\n                f\"\\n\\nNeuron {i + 1}\\nExplanation of neuron {i + 1} behavior: {EXPLANATION_PREFIX} \"",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:353-373"
    },
    "249": {
        "file_id": 16,
        "content": "This code creates a prompt for predicting neuron activations using a few-shot example set. It adds a system message with instructions on how to analyze the neurons in a neural network and then appends user messages for each example in the set, including the example itself along with an explanation of the neuron's behavior.",
        "type": "comment"
    },
    "250": {
        "file_id": 16,
        "content": "                f\"{example.explanation}\",\n            )\n            formatted_activation_records = format_activation_records(\n                example.activation_records,\n                calculate_max_activation(example.activation_records),\n                start_indices=example.first_revealed_activation_indices,\n            )\n            prompt_builder.add_message(\n                Role.ASSISTANT, f\"\\nActivations: {formatted_activation_records}\\n\"\n            )\n        prompt_builder.add_message(\n            Role.USER,\n            f\"\\n\\nNeuron {len(few_shot_examples) + 1}\\nExplanation of neuron \"\n            f\"{len(few_shot_examples) + 1} behavior: {EXPLANATION_PREFIX} \"\n            f\"{self.explanation.strip()}\",\n        )\n        prompt_builder.add_message(\n            Role.ASSISTANT, f\"\\nActivations: {format_sequences_for_simulation([tokens])}\"\n        )\n        return prompt_builder.build(self.prompt_format)\nclass ExplanationTokenByTokenSimulator(NeuronSimulator):\n    \"\"\"\n    Simulate neuron behavior based on an explanation.",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:374-399"
    },
    "251": {
        "file_id": 16,
        "content": "This code snippet is part of a Neuron Simulator that simulates neuron behavior based on an explanation. It adds formatted activation records and messages to a prompt builder, including explanations of neuron behavior for few-shot examples.",
        "type": "comment"
    },
    "252": {
        "file_id": 16,
        "content": "    Unlike ExplanationNeuronSimulator, this class uses one few-shot prompt per token to calculate\n    expected activations. This is slower. This class gets a one-token completion and calculates an\n    expected value from that token's logprobs.\n    \"\"\"\n    def __init__(\n        self,\n        model_name: str,\n        explanation: str,\n        max_concurrent: Optional[int] = 10,\n        few_shot_example_set: FewShotExampleSet = FewShotExampleSet.NEWER,\n        prompt_format: PromptFormat = PromptFormat.INSTRUCTION_FOLLOWING,\n        cache: bool = False,\n    ):\n        assert (\n            few_shot_example_set != FewShotExampleSet.ORIGINAL\n        ), \"This simulator doesn't support the ORIGINAL few-shot example set.\"\n        self.api_client = ApiClient(\n            model_name=model_name, max_concurrent=max_concurrent, cache=cache\n        )\n        self.explanation = explanation\n        self.few_shot_example_set = few_shot_example_set\n        self.prompt_format = prompt_format\n    async def simulate(\n        self,",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:401-426"
    },
    "253": {
        "file_id": 16,
        "content": "This class initializes an API client and takes inputs like model name, explanation, max concurrent requests, example set, prompt format, and cache. It asserts that the few-shot example set is not ORIGINAL since this simulator doesn't support it. Then, it performs a simulation using one token prompt per token and calculates expected values from log probabilities. This method is slower compared to ExplanationNeuronSimulator.",
        "type": "comment"
    },
    "254": {
        "file_id": 16,
        "content": "        tokens: Sequence[str],\n    ) -> SequenceSimulation:\n        responses_by_token = await asyncio.gather(\n            *[\n                self._get_activation_stats_for_single_token(tokens, self.explanation, token_index)\n                for token_index in range(len(tokens))\n            ]\n        )\n        expected_values, distribution_values, distribution_probabilities = [], [], []\n        for response in responses_by_token:\n            activation_logprobs = response[\"choices\"][0][\"logprobs\"][\"top_logprobs\"][0]\n            (\n                norm_probabilities_by_distribution_value,\n                expected_value,\n            ) = compute_predicted_activation_stats_for_token(\n                activation_logprobs,\n            )\n            distribution_values.append(\n                [float(v) for v in norm_probabilities_by_distribution_value.keys()]\n            )\n            distribution_probabilities.append(\n                list(norm_probabilities_by_distribution_value.values())\n            )\n            expected_values.append(expected_value)",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:427-450"
    },
    "255": {
        "file_id": 16,
        "content": "This function collects activation statistics for each token in the input sequence and then normalizes the probabilities by distribution values, expected values, and appends them to their respective lists.",
        "type": "comment"
    },
    "256": {
        "file_id": 16,
        "content": "        result = SequenceSimulation(\n            tokens=list(tokens),  # SequenceSimulation expects List type\n            expected_activations=expected_values,\n            activation_scale=ActivationScale.SIMULATED_NORMALIZED_ACTIVATIONS,\n            distribution_values=distribution_values,\n            distribution_probabilities=distribution_probabilities,\n        )\n        logger.debug(\"result in score_explanation_by_activations is %s\", result)\n        return result\n    async def _get_activation_stats_for_single_token(\n        self,\n        tokens: Sequence[str],\n        explanation: str,\n        token_index_to_score: int,\n    ) -> dict:\n        prompt = self.make_single_token_simulation_prompt(\n            tokens,\n            explanation,\n            token_index_to_score=token_index_to_score,\n        )\n        return await self.api_client.make_request(\n            prompt=prompt, max_tokens=1, echo=False, logprobs=15\n        )\n    def _add_single_token_simulation_subprompt(\n        self,\n        prompt_builder: PromptBuilder,",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:452-479"
    },
    "257": {
        "file_id": 16,
        "content": "This code is creating a SequenceSimulation object and logging its result. It also defines an asynchronous function that retrieves activation statistics for a single token using API client, and adds a subprompt to a prompt builder.",
        "type": "comment"
    },
    "258": {
        "file_id": 16,
        "content": "        activation_record: ActivationRecord,\n        neuron_index: int,\n        explanation: str,\n        token_index_to_score: int,\n        end_of_prompt: bool,\n    ) -> None:\n        trimmed_activation_record = ActivationRecord(\n            tokens=activation_record.tokens[: token_index_to_score + 1],\n            activations=activation_record.activations[: token_index_to_score + 1],\n        )\n        prompt_builder.add_message(\n            Role.USER,\n            f\"\"\"\nNeuron {neuron_index}\nExplanation of neuron {neuron_index} behavior: {EXPLANATION_PREFIX} {explanation.strip()}\nText:\n{\"\".join(trimmed_activation_record.tokens)}\nLast token in the text:\n{trimmed_activation_record.tokens[-1]}\nLast token activation, considering the token in the context in which it appeared in the text:\n\"\"\",\n        )\n        if not end_of_prompt:\n            normalized_activations = normalize_activations(\n                trimmed_activation_record.activations, calculate_max_activation([activation_record])\n            )\n            prompt_builder.add_message(",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:480-508"
    },
    "259": {
        "file_id": 16,
        "content": "Creating trimmed activation record and adding messages to the prompt builder.",
        "type": "comment"
    },
    "260": {
        "file_id": 16,
        "content": "                Role.ASSISTANT, str(normalized_activations[-1]) + (\"\" if end_of_prompt else \"\\n\\n\")\n            )\n    def make_single_token_simulation_prompt(\n        self,\n        tokens: Sequence[str],\n        explanation: str,\n        token_index_to_score: int,\n    ) -> Union[str, list[HarmonyMessage]]:\n        \"\"\"Make a few-shot prompt for predicting the neuron's activation on a single token.\"\"\"\n        assert explanation != \"\"\n        prompt_builder = PromptBuilder()\n        prompt_builder.add_message(\n            Role.SYSTEM,\n            \"\"\"We're studying neurons in a neural network. Each neuron looks for some particular thing in a short document. Look at  an explanation of what the neuron does, and try to predict its activations on a particular token.\nThe activation format is token<tab>activation, and activations range from 0 to 10. Most activations will be 0.\n\"\"\",\n        )\n        few_shot_examples = self.few_shot_example_set.get_examples()\n        for i, example in enumerate(few_shot_examples):",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:509-531"
    },
    "261": {
        "file_id": 16,
        "content": "This function generates a prompt for predicting the neuron's activation on a single token. It involves adding a system message explaining the task and providing few-shot examples.",
        "type": "comment"
    },
    "262": {
        "file_id": 16,
        "content": "            prompt_builder.add_message(\n                Role.USER,\n                f\"Neuron {i + 1}\\nExplanation of neuron {i + 1} behavior: {EXPLANATION_PREFIX} \"\n                f\"{example.explanation}\\n\",\n            )\n            formatted_activation_records = format_activation_records(\n                example.activation_records,\n                calculate_max_activation(example.activation_records),\n                start_indices=None,\n            )\n            prompt_builder.add_message(\n                Role.ASSISTANT,\n                f\"Activations: {formatted_activation_records}\\n\\n\",\n            )\n        prompt_builder.add_message(\n            Role.SYSTEM,\n            \"Now, we're going predict the activation of a new neuron on a single token, \"\n            \"following the same rules as the examples above. Activations still range from 0 to 10.\",\n        )\n        single_token_example = self.few_shot_example_set.get_single_token_prediction_example()\n        assert single_token_example.token_index_to_score is not None",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:532-553"
    },
    "263": {
        "file_id": 16,
        "content": "Generating a prompt to explain neuron behavior and visualize activation records for an example, then adding a message asking to predict the activation of a new neuron on a single token following the same rules.",
        "type": "comment"
    },
    "264": {
        "file_id": 16,
        "content": "        self._add_single_token_simulation_subprompt(\n            prompt_builder,\n            single_token_example.activation_records[0],\n            len(few_shot_examples) + 1,\n            explanation,\n            token_index_to_score=single_token_example.token_index_to_score,\n            end_of_prompt=False,\n        )\n        activation_record = ActivationRecord(\n            tokens=list(tokens[: token_index_to_score + 1]),  # ActivationRecord expects List type.\n            activations=[0.0] * len(tokens),\n        )\n        self._add_single_token_simulation_subprompt(\n            prompt_builder,\n            activation_record,\n            len(few_shot_examples) + 2,\n            explanation,\n            token_index_to_score,\n            end_of_prompt=True,\n        )\n        return prompt_builder.build(self.prompt_format, allow_extra_system_messages=True)\ndef _format_record_for_logprob_free_simulation(\n    activation_record: ActivationRecord,\n    include_activations: bool = False,\n    max_activation: Optional[float] = None,",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:554-581"
    },
    "265": {
        "file_id": 16,
        "content": "This code adds two subprompts to a prompt builder, one for a single token example and another for an activation record. It then returns the final formatted prompt.",
        "type": "comment"
    },
    "266": {
        "file_id": 16,
        "content": ") -> str:\n    response = \"\"\n    if include_activations:\n        assert max_activation is not None\n        assert len(activation_record.tokens) == len(\n            activation_record.activations\n        ), f\"{len(activation_record.tokens)=}, {len(activation_record.activations)=}\"\n        normalized_activations = normalize_activations(\n            activation_record.activations, max_activation=max_activation\n        )\n    for i, token in enumerate(activation_record.tokens):\n        # We use a weird unicode character here to make it easier to parse the response (can split on \"༗\\n\").\n        if include_activations:\n            response += f\"{token}\\t{normalized_activations[i]}༗\\n\"\n        else:\n            response += f\"{token}\\t༗\\n\"\n    return response\ndef _parse_no_logprobs_completion(\n    completion: str,\n    tokens: Sequence[str],\n) -> Sequence[int]:\n    \"\"\"\n    Parse a completion into a list of simulated activations. If the model did not faithfully\n    reproduce the token sequence, return a list of 0s. If the model's activation for a token",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:582-607"
    },
    "267": {
        "file_id": 16,
        "content": "This code is parsing a completion into a list of simulated activations. If the model did not faithfully reproduce the token sequence, it returns a list of 0s. It also includes an optional normalization of activations based on max_activation parameter.",
        "type": "comment"
    },
    "268": {
        "file_id": 16,
        "content": "    is not an integer betwee 0 and 10, substitute 0.\n    Args:\n        completion: completion from the API\n        tokens: list of tokens as strings in the sequence where the neuron is being simulated\n    \"\"\"\n    zero_prediction = [0] * len(tokens)\n    token_lines = completion.strip(\"\\n\").split(\"༗\\n\")\n    start_line_index = None\n    for i, token_line in enumerate(token_lines):\n        if token_line.startswith(f\"{tokens[0]}\\t\"):\n            start_line_index = i\n            break\n    # If we didn't find the first token, or if the number of lines in the completion doesn't match\n    # the number of tokens, return a list of 0s.\n    if start_line_index is None or len(token_lines) - start_line_index != len(tokens):\n        return zero_prediction\n    predicted_activations = []\n    for i, token_line in enumerate(token_lines[start_line_index:]):\n        if not token_line.startswith(f\"{tokens[i]}\\t\"):\n            return zero_prediction\n        predicted_activation = token_line.split(\"\\t\")[1]\n        if predicted_activation not in VALID_ACTIVATION_TOKENS:",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:608-631"
    },
    "269": {
        "file_id": 16,
        "content": "This code checks if the first token is present in the completion and if the number of lines matches the number of tokens. If not, it returns a list of 0s. It then extracts the predicted activations for each token from the completion.",
        "type": "comment"
    },
    "270": {
        "file_id": 16,
        "content": "            predicted_activations.append(0)\n        else:\n            predicted_activations.append(int(predicted_activation))\n    return predicted_activations\nclass LogprobFreeExplanationTokenSimulator(NeuronSimulator):\n    \"\"\"\n    Simulate neuron behavior based on an explanation.\n    Unlike ExplanationNeuronSimulator and ExplanationTokenByTokenSimulator, this class does not rely on\n    logprobs to calculate expected activations. Instead, it uses a few-shot prompt that displays all of the\n    tokens at once, and request that the model repeat the tokens with the activations appended. Sampling\n    is with temperature = 0. Thus, the activations are deterministic. Also, each activation for a token\n    is a function of all the activations that came previously and all of the tokens in the sequence, not\n    just the current and previous tokens. In the case where the model does not faithfully reproduce the\n    token sequence, the simulator will return a response where every predicted activation is 0. Example prompt as follows:",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:632-648"
    },
    "271": {
        "file_id": 16,
        "content": "The code appends deterministic activations to the explanation token sequence.",
        "type": "comment"
    },
    "272": {
        "file_id": 16,
        "content": "    Explanation: Explanation 1\n    Sequence 1 Tokens Without Activations:\n    A\\t_\n    B\\t_\n    C\\t_\n    Sequence 1 Tokens With Activations:\n    A\\t4_\n    B\\t10_\n    C\\t0_\n    Sequence 2 Tokens Without Activations:\n    D\\t_\n    E\\t_\n    F\\t_\n    Sequence 2 Tokens With Activations:\n    D\\t3_\n    E\\t6_\n    F\\t9_\n    Explanation: Explanation 2\n    Sequence 1 Tokens Without Activations:\n    G\\t_\n    H\\t_\n    I\\t_\n    Sequence 1 Tokens With Activations:\n    <start sampling here>\n    G\\t2_\n    H\\t0_\n    I\\t3_\n    \"\"\"\n    def __init__(\n        self,\n        model_name: str,\n        explanation: str,\n        max_concurrent: Optional[int] = 10,\n        few_shot_example_set: FewShotExampleSet = FewShotExampleSet.NEWER,\n        prompt_format: PromptFormat = PromptFormat.HARMONY_V4,\n        cache: bool = False,\n    ):\n        assert (\n            few_shot_example_set != FewShotExampleSet.ORIGINAL\n        ), \"This simulator doesn't support the ORIGINAL few-shot example set.\"\n        self.api_client = ApiClient(\n            model_name=model_name, max_concurrent=max_concurrent, cache=cache",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:650-706"
    },
    "273": {
        "file_id": 16,
        "content": "This code is initializing an instance of a simulator. It takes the model name, explanation, maximum concurrent samples, few-shot example set (not ORIGINAL), prompt format, and cache settings as parameters. The assert statement ensures that the few-shot example set is not ORIGINAL because this simulator doesn't support it. It then initializes an instance of ApiClient with the given model name, maximum concurrent samples, and cache settings.",
        "type": "comment"
    },
    "274": {
        "file_id": 16,
        "content": "        )\n        self.explanation = explanation\n        self.few_shot_example_set = few_shot_example_set\n        self.prompt_format = prompt_format\n    async def simulate(\n        self,\n        tokens: Sequence[str],\n    ) -> SequenceSimulation:\n        prompt = self._make_simulation_prompt(\n            tokens,\n            self.explanation,\n        )\n        response = await self.api_client.make_request(\n            prompt=prompt, echo=False, max_tokens=1000\n        )\n        assert len(response[\"choices\"]) == 1\n        choice = response[\"choices\"][0]\n        if self.prompt_format == PromptFormat.HARMONY_V4:\n            completion = choice[\"message\"][\"content\"]\n        elif self.prompt_format in [PromptFormat.NONE, PromptFormat.INSTRUCTION_FOLLOWING]:\n            completion = choice[\"text\"]\n        else:\n            raise ValueError(f\"Unhandled prompt format {self.prompt_format}\")\n        predicted_activations = _parse_no_logprobs_completion(completion, tokens)\n        result = SequenceSimulation(\n            activation_scale=ActivationScale.SIMULATED_NORMALIZED_ACTIVATIONS,",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:707-736"
    },
    "275": {
        "file_id": 16,
        "content": "Code creates a simulation prompt, sends it to API client for processing, and stores the result.",
        "type": "comment"
    },
    "276": {
        "file_id": 16,
        "content": "            expected_activations=predicted_activations,\n            # Since the predicted activation is just a sampled token, we don't have a distribution.\n            distribution_values=None,\n            distribution_probabilities=None,\n            tokens=list(tokens),  # SequenceSimulation expects List type\n        )\n        logger.debug(\"result in score_explanation_by_activations is %s\", result)\n        return result\n    def _make_simulation_prompt(\n        self,\n        tokens: Sequence[str],\n        explanation: str,\n    ) -> Union[str, list[HarmonyMessage]]:\n        \"\"\"Make a few-shot prompt for predicting the neuron's activations on a sequence.\"\"\"\n        assert explanation != \"\"\n        prompt_builder = PromptBuilder(allow_extra_system_messages=True)\n        prompt_builder.add_message(\n            Role.SYSTEM,\n            \"\"\"We're studying neurons in a neural network. Each neuron looks for some particular thing in a short document. Look at  an explanation of what the neuron does, and try to predict its activations on a particular token.",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:737-756"
    },
    "277": {
        "file_id": 16,
        "content": "Creating a SimulationResult object with expected activations, and None distribution values and probabilities.\n\nFunction to build a simulation prompt using PromptBuilder and add a system message about studying neurons in neural networks.",
        "type": "comment"
    },
    "278": {
        "file_id": 16,
        "content": "The activation format is token<tab>activation, and activations range from 0 to 10. Most activations will be 0.\nFor each sequence, you will see the tokens in the sequence where the activations are left blank. You will print the exact same tokens verbatim, but with the activations filled in according to the explanation.\n\"\"\",\n        )\n        few_shot_examples = self.few_shot_example_set.get_examples()\n        for i, example in enumerate(few_shot_examples):\n            few_shot_example_max_activation = calculate_max_activation(example.activation_records)\n            prompt_builder.add_message(\n                Role.USER,\n                f\"Neuron {i + 1}\\nExplanation of neuron {i + 1} behavior: {EXPLANATION_PREFIX} \"\n                f\"{example.explanation}\\n\\n\"\n                f\"Sequence 1 Tokens without Activations:\\n{_format_record_for_logprob_free_simulation(example.activation_records[0], include_activations=False)}\\n\\n\"\n                f\"Sequence 1 Tokens with Activations:\\n\",\n            )\n            prompt_builder.add_message(",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:758-774"
    },
    "279": {
        "file_id": 16,
        "content": "This code generates explanations for neuron behavior in a sequence, and for each neuron, it shows the tokens with and without activations. Activation records are used to determine the max activation for that neuron. The output includes an explanation prefix, tokens without and with activations for Sequence 1, and is added to a prompt builder.",
        "type": "comment"
    },
    "280": {
        "file_id": 16,
        "content": "                Role.ASSISTANT,\n                f\"{_format_record_for_logprob_free_simulation(example.activation_records[0], include_activations=True, max_activation=few_shot_example_max_activation)}\\n\\n\",\n            )\n            for record_index, record in enumerate(example.activation_records[1:]):\n                prompt_builder.add_message(\n                    Role.USER,\n                    f\"Sequence {record_index + 2} Tokens without Activations:\\n{_format_record_for_logprob_free_simulation(record, include_activations=False)}\\n\\n\"\n                    f\"Sequence {record_index + 2} Tokens with Activations:\\n\",\n                )\n                prompt_builder.add_message(\n                    Role.ASSISTANT,\n                    f\"{_format_record_for_logprob_free_simulation(record, include_activations=True, max_activation=few_shot_example_max_activation)}\\n\\n\",\n                )\n        neuron_index = len(few_shot_examples) + 1\n        prompt_builder.add_message(\n            Role.USER,\n            f\"Neuron {neuron_index}\\nExplanation of neuron {neuron_index} behavior: {EXPLANATION_PREFIX} \"",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:775-793"
    },
    "281": {
        "file_id": 16,
        "content": "This code is building a prompt for an AI model by adding messages to the prompt_builder. It iterates through activation records of an example, adding information about tokens with and without activations for each record. Finally, it adds a message for the next neuron index with its explanation.",
        "type": "comment"
    },
    "282": {
        "file_id": 16,
        "content": "            f\"{explanation}\\n\\n\"\n            f\"Sequence 1 Tokens without Activations:\\n{_format_record_for_logprob_free_simulation(ActivationRecord(tokens=tokens, activations=[]), include_activations=False)}\\n\\n\"\n            f\"Sequence 1 Tokens with Activations:\\n\",\n        )\n        return prompt_builder.build(self.prompt_format)",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/simulator.py:794-798"
    },
    "283": {
        "file_id": 16,
        "content": "This code generates a formatted explanation for sequence 1 tokens without and with activations, and returns it in a prompt format.",
        "type": "comment"
    },
    "284": {
        "file_id": 17,
        "content": "/neuron-explainer/neuron_explainer/explanations/test_explainer.py",
        "type": "filepath"
    },
    "285": {
        "file_id": 17,
        "content": "The code initializes an event loop, tests explanation formats with generated prompts and neuron behavior visualization using GPT-4 and Harmony V4 for token lists up to 20 tokens.",
        "type": "summary"
    },
    "286": {
        "file_id": 17,
        "content": "import asyncio\nfrom typing import Any\nfrom neuron_explainer.explanations.explainer import (\n    TokenActivationPairExplainer,\n    TokenSpaceRepresentationExplainer,\n)\nfrom neuron_explainer.explanations.few_shot_examples import TEST_EXAMPLES, FewShotExampleSet\nfrom neuron_explainer.explanations.prompt_builder import HarmonyMessage, PromptFormat, Role\nfrom neuron_explainer.explanations.token_space_few_shot_examples import (\n    TokenSpaceFewShotExampleSet,\n)\ndef setup_module(unused_module: Any) -> None:\n    # Make sure we have an event loop, since the attempt to create the Semaphore in\n    # ResearchApiClient will fail without it.\n    loop = asyncio.new_event_loop()\n    asyncio.set_event_loop(loop)\ndef test_if_formatting() -> None:\n    expected_prompt = \"\"\"We're studying neurons in a neural network. Each neuron looks for some particular thing in a short document. Look at the parts of the document the neuron activates for and summarize in a single sentence what the neuron is looking for. Don't list examples of words.",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/test_explainer.py:1-23"
    },
    "287": {
        "file_id": 17,
        "content": "Setting up the event loop for async operations.",
        "type": "comment"
    },
    "288": {
        "file_id": 17,
        "content": "The activation format is token<tab>activation. Activation values range from 0 to 10. A neuron finding what it's looking for is represented by a non-zero activation value. The higher the activation value, the stronger the match.\nNeuron 1\nActivations:\n<start>\na\t10\nb\t0\nc\t0\n<end>\n<start>\nd\t0\ne\t10\nf\t0\n<end>\nExplanation of neuron 1 behavior: the main thing this neuron does is find vowels.\nNeuron 2\nActivations:\n<start>\na\t10\nb\t0\nc\t0\n<end>\n<start>\nd\t0\ne\t10\nf\t0\n<end>\nExplanation of neuron 2 behavior:<|endofprompt|> the main thing this neuron does is find\"\"\"\n    explainer = TokenActivationPairExplainer(\n        model_name=\"text-davinci-003\",\n        prompt_format=PromptFormat.INSTRUCTION_FOLLOWING,\n        few_shot_example_set=FewShotExampleSet.TEST,\n    )\n    prompt = explainer.make_explanation_prompt(\n        all_activation_records=TEST_EXAMPLES[0].activation_records,\n        max_activation=1.0,\n        max_tokens_for_completion=20,\n    )\n    assert prompt == expected_prompt\ndef test_harmony_format() -> None:\n    expected_prompt = [\n        HarmonyMessage(",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/test_explainer.py:25-73"
    },
    "289": {
        "file_id": 17,
        "content": "This code initializes an explainer object with specific parameters and then generates a test prompt using the provided activation records. The generated prompt is then asserted to be equal to the expected prompt. The main purpose of this code is to test whether the explanation format matches the expected output for a given set of activation records.",
        "type": "comment"
    },
    "290": {
        "file_id": 17,
        "content": "            role=Role.SYSTEM,\n            content=\"\"\"We're studying neurons in a neural network. Each neuron looks for some particular thing in a short document. Look at the parts of the document the neuron activates for and summarize in a single sentence what the neuron is looking for. Don't list examples of words.\nThe activation format is token<tab>activation. Activation values range from 0 to 10. A neuron finding what it's looking for is represented by a non-zero activation value. The higher the activation value, the stronger the match.\"\"\",\n        ),\n        HarmonyMessage(\n            role=Role.USER,\n            content=\"\"\"\nNeuron 1\nActivations:\n<start>\na\t10\nb\t0\nc\t0\n<end>\n<start>\nd\t0\ne\t10\nf\t0\n<end>\nExplanation of neuron 1 behavior: the main thing this neuron does is find\"\"\",\n        ),\n        HarmonyMessage(\n            role=Role.ASSISTANT,\n            content=\" vowels.\",\n        ),\n        HarmonyMessage(\n            role=Role.USER,\n            content=\"\"\"\nNeuron 2\nActivations:\n<start>\na\t10\nb\t0\nc\t0\n<end>\n<start>\nd\t0",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/test_explainer.py:74-114"
    },
    "291": {
        "file_id": 17,
        "content": "Code explains the neuron's behavior in a neural network, showing activation values for tokens and summarizing what each neuron is looking for.",
        "type": "comment"
    },
    "292": {
        "file_id": 17,
        "content": "e\t10\nf\t0\n<end>\nExplanation of neuron 2 behavior: the main thing this neuron does is find\"\"\",\n        ),\n    ]\n    explainer = TokenActivationPairExplainer(\n        model_name=\"gpt-4\",\n        prompt_format=PromptFormat.HARMONY_V4,\n        few_shot_example_set=FewShotExampleSet.TEST,\n    )\n    prompt = explainer.make_explanation_prompt(\n        all_activation_records=TEST_EXAMPLES[0].activation_records,\n        max_activation=1.0,\n        max_tokens_for_completion=20,\n    )\n    assert isinstance(prompt, list)\n    assert isinstance(prompt[0], dict)  # Really a HarmonyMessage\n    for actual_message, expected_message in zip(prompt, expected_prompt):\n        assert actual_message[\"role\"] == expected_message[\"role\"]\n        assert actual_message[\"content\"] == expected_message[\"content\"]\n    assert prompt == expected_prompt\ndef test_token_space_explainer_if_formatting() -> None:\n    expected_prompt = \"\"\"We're studying neurons in a neural network. Each neuron looks for some particular kind of token (which can be a w",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/test_explainer.py:115-143"
    },
    "293": {
        "file_id": 17,
        "content": "This code initializes an explainer object, sets the model name to \"gpt-4\", prompt format to Harmony_v4, and few shot example set to TEST. Then it creates a list of prompts for explanation by calling `make_explanation_prompt` function with a list of activation records, max activation, and max tokens for completion. The code asserts that the resulting prompt is a list and each item in the list is a dictionary (HarmonyMessage) and compares it with the expected_prompt. Finally, it tests if the prompt matches the expected_prompt by comparing their contents.",
        "type": "comment"
    },
    "294": {
        "file_id": 17,
        "content": "ord, or part of a word). Look at the tokens the neuron activates for (listed below) and summarize in a single sentence what the neuron is looking for. Don't list examples of words.\nTokens:\n'these', ' are', ' tokens'\nExplanation:\nThis neuron is looking for this is a test explanation.\nTokens:\n'foo', 'bar', 'baz'\nExplanation:\n<|endofprompt|>This neuron is looking for\"\"\"\n    explainer = TokenSpaceRepresentationExplainer(\n        model_name=\"text-davinci-002\",\n        prompt_format=PromptFormat.INSTRUCTION_FOLLOWING,\n        use_few_shot=True,\n        few_shot_example_set=TokenSpaceFewShotExampleSet.TEST,\n    )\n    prompt = explainer.make_explanation_prompt(\n        tokens=[\"foo\", \"bar\", \"baz\"],\n        max_tokens_for_completion=20,\n    )\n    assert prompt == expected_prompt\ndef test_token_space_explainer_harmony_formatting() -> None:\n    expected_prompt = [\n        HarmonyMessage(\n            role=Role.SYSTEM,\n            content=\"We're studying neurons in a neural network. Each neuron looks for some particular k",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/test_explainer.py:143-179"
    },
    "295": {
        "file_id": 17,
        "content": "This code initializes a TokenSpaceRepresentationExplainer with specific parameters and then uses it to generate an explanation prompt given a set of tokens. The expected output is compared to the generated prompt in the test case.",
        "type": "comment"
    },
    "296": {
        "file_id": 17,
        "content": "ind of token (which can be a word, or part of a word). Look at the tokens the neuron activates for (listed below) and summarize in a single sentence what the neuron is looking for. Don't list examples of words.\",\n        ),\n        HarmonyMessage(\n            role=Role.USER,\n            content=\"\"\"\nTokens:\n'these', ' are', ' tokens'\nExplanation:\nThis neuron is looking for\"\"\",\n        ),\n        HarmonyMessage(\n            role=Role.ASSISTANT,\n            content=\" this is a test explanation.\",\n        ),\n        HarmonyMessage(\n            role=Role.USER,\n            content=\"\"\"\nTokens:\n'foo', 'bar', 'baz'\nExplanation:\nThis neuron is looking for\"\"\",\n        ),\n    ]\n    explainer = TokenSpaceRepresentationExplainer(\n        model_name=\"gpt-4\",\n        prompt_format=PromptFormat.HARMONY_V4,\n        use_few_shot=True,\n        few_shot_example_set=TokenSpaceFewShotExampleSet.TEST,\n    )\n    prompt = explainer.make_explanation_prompt(\n        tokens=[\"foo\", \"bar\", \"baz\"],\n        max_tokens_for_completion=20,\n    )\n    assert isinstance(prompt, list)",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/test_explainer.py:179-222"
    },
    "297": {
        "file_id": 17,
        "content": "The code initializes a TokenSpaceRepresentationExplainer with GPT-4 model and Harmony V4 prompt format. It also uses few-shot learning with the test example set and generates an explanation prompt for the tokens 'foo', 'bar', and 'baz'. The explanation prompt will be in list format, and its length should not exceed 20 tokens.",
        "type": "comment"
    },
    "298": {
        "file_id": 17,
        "content": "    assert isinstance(prompt[0], dict)  # Really a HarmonyMessage\n    for actual_message, expected_message in zip(prompt, expected_prompt):\n        assert actual_message[\"role\"] == expected_message[\"role\"]\n        assert actual_message[\"content\"] == expected_message[\"content\"]\n    assert prompt == expected_prompt",
        "type": "code",
        "location": "/neuron-explainer/neuron_explainer/explanations/test_explainer.py:223-227"
    },
    "299": {
        "file_id": 17,
        "content": "Checking if the prompt is a list of HarmonyMessages and if each message's role and content match the expected values.",
        "type": "comment"
    }
}